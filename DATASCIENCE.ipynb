{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "16xMy4ZNLQrfg6h3D95KygtLpGanX4rTR",
      "authorship_tag": "ABX9TyNPnP+/7pk5l7xZM0X10Y2N",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/yashh0316/datascienCeproject/blob/main/DATASCIENCE.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#1: Basics of Coding R/Python"
      ],
      "metadata": {
        "id": "02mmGB8TASyj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#1 Using Comments R/Python\n",
        "\n",
        "#2 executing commands\n",
        "\n",
        "result = \"DATA SCIENCE \"\n",
        "print(result)\n",
        "\n",
        "#3 import package\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "#4 Getting Data into python\n",
        "\n",
        "path = \"/content/drive/MyDrive/dataset/Auto Sales data.csv\"\n",
        "data = pd.read_csv(path)\n",
        "#print(data)\n",
        "\n",
        "#5 Saving output\n",
        "\n",
        "data.to_csv('output.csv', index=False)\n",
        "\n",
        "#6 Access and print specific variables/columns\n",
        "\n",
        "print(data['ORDERNUMBER'])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f6N0cIyEAmWV",
        "outputId": "fd97b452-8262-4f38-bc30-961877a1eb79"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DATA SCIENCE \n",
            "0      10107\n",
            "1      10121\n",
            "2      10134\n",
            "3      10145\n",
            "4      10168\n",
            "       ...  \n",
            "103    10167\n",
            "104    10178\n",
            "105    10186\n",
            "106    10197\n",
            "107    10222\n",
            "Name: ORDERNUMBER, Length: 108, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#2: DATA PREPARATION"
      ],
      "metadata": {
        "id": "sj6dXrBAFha8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#1 How to Add an Index Field Using R/Python\n",
        "\n",
        "index = pd.DataFrame({\"Index\": data.index})\n",
        "data = pd.concat([index, data], axis=1)\n",
        "print(data)\n",
        "\n",
        "#2 How to Change Misleading Field Values Using R/Python\n",
        "\n",
        "misleading_values = {34: 40, 50: 60, 75: 80}\n",
        "data['QUANTITYORDERED'].replace(misleading_values, inplace=True)\n",
        "print(data['QUANTITYORDERED'])\n",
        "\n",
        "#3 How to Re Express Categorical Field Values Using R/Python\n",
        "\n",
        "#data['DEALSIZE'] = data['DEALSIZE'].replace('large', 'small','medium')\n",
        "#data = pd.get_dummies(data, columns=['DEALSIZE'])\n",
        "#print(data['DEALSIZE'])\n",
        "\n",
        "\n",
        "print( ' How to Standardise Numeric Fields Using R/Python' )\n",
        "\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "numerical_columns_to_standardize = ['QUANTITYORDERED', 'PRICEEACH']\n",
        "\n",
        "\n",
        "scaler = StandardScaler()\n",
        "\n",
        "data[numerical_columns_to_standardize] = scaler.fit_transform(data[numerical_columns_to_standardize])\n",
        "\n",
        "\n",
        "standardized_file_path = 'standardized_dataset.csv'\n",
        "data.to_csv(standardized_file_path, index=False)\n",
        "print(data)\n",
        "print(\"\\nSummary Statistics After Standardization:\")\n",
        "print(data[['QUANTITYORDERED', 'PRICEEACH']].describe())\n",
        "\n",
        "\n",
        "# 5 How to Identify Outliers Using R/Python\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "numerical_columns = ['QUANTITYORDERED', 'PRICEEACH']\n",
        "\n",
        "z_scores = np.abs((data[numerical_columns] - data[numerical_columns].mean()) / data[numerical_columns].std())\n",
        "\n",
        "z_score_threshold = 1\n",
        "\n",
        "outliers = (z_scores > z_score_threshold).any(axis=1)\n",
        "\n",
        "print(\"Rows with outliers:\")\n",
        "print(data[outliers])\n",
        "\n",
        "outliers_removed_file_path = 'dataset_without_outliers.csv'\n",
        "data[~outliers].to_csv(outliers_removed_file_path, index=False)\n",
        "\n",
        "print(\"Rows with outliers:\")\n",
        "print(data[outliers])\n",
        "\n",
        "standardized_file_path = 'standardized_dataset_with_outliers.csv'\n",
        "data.to_csv(standardized_file_path, index=False)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vMtiaYOfF5Bu",
        "outputId": "4284cd4d-28b0-4b81-faeb-de9161c16a82"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     Index  ORDERNUMBER  QUANTITYORDERED  PRICEEACH  ORDERLINENUMBER    SALES  \\\n",
            "0        0        10107               30      95.70                2  2871.00   \n",
            "1        1        10121               34      81.35                5  2765.90   \n",
            "2        2        10134               41      94.74                2  3884.34   \n",
            "3        3        10145               45      83.26                6  3746.70   \n",
            "4        4        10168               36      96.66                1  3479.76   \n",
            "..     ...          ...              ...        ...              ...      ...   \n",
            "103    103        10167               44     134.64                9  5924.16   \n",
            "104    104        10178               24     145.52               12  3492.48   \n",
            "105    105        10186               26     148.24                9  3854.24   \n",
            "106    106        10197               45     118.32                6  5324.40   \n",
            "107    107        10222               49     122.40               12  5997.60   \n",
            "\n",
            "     DAYS_SINCE_LASTORDER     STATUS   PRODUCTLINE  MSRP PRODUCTCODE  \\\n",
            "0                     828    Shipped   Motorcycles    95    S10_1678   \n",
            "1                     757    Shipped   Motorcycles    95    S10_1678   \n",
            "2                     703    Shipped   Motorcycles    95    S10_1678   \n",
            "3                     649    Shipped   Motorcycles    95    S10_1678   \n",
            "4                     586    Shipped   Motorcycles    95    S10_1678   \n",
            "..                    ...        ...           ...   ...         ...   \n",
            "103                   690  Cancelled  Classic Cars   136    S10_4757   \n",
            "104                   675    Shipped  Classic Cars   136    S10_4757   \n",
            "105                   670    Shipped  Classic Cars   136    S10_4757   \n",
            "106                   659    Shipped  Classic Cars   136    S10_4757   \n",
            "107                   575    Shipped  Classic Cars   136    S10_4757   \n",
            "\n",
            "                       CUSTOMERNAME             PHONE  \\\n",
            "0                 Land of Toys Inc.        2125557818   \n",
            "1                Reims Collectables        26.47.1555   \n",
            "2                   Lyon Souveniers  +33 1 46 62 7555   \n",
            "3                 Toys4GrownUps.com        6265557265   \n",
            "4              Technics Stores Inc.        6505556809   \n",
            "..                              ...               ...   \n",
            "103         Scandinavian Gift Ideas      0695-34 6555   \n",
            "104                    Alpha Cognac        61.77.6555   \n",
            "105  Double Decker Gift Stores, Ltd    (171) 555-7555   \n",
            "106              Enaco Distributors     (93) 203 4555   \n",
            "107    Collectable Mini Designs Co.        7605558146   \n",
            "\n",
            "                      ADDRESSLINE1        CITY POSTALCODE COUNTRY  \\\n",
            "0          897 Long Airport Avenue         NYC      10022     USA   \n",
            "1               59 rue de l'Abbaye       Reims      51100  France   \n",
            "2    27 rue du Colonel Pierre Avia       Paris      75508  France   \n",
            "3               78934 Hillside Dr.    Pasadena      90003     USA   \n",
            "4                9408 Furth Circle  Burlingame      94217     USA   \n",
            "..                             ...         ...        ...     ...   \n",
            "103                   ?kergatan 24       Boras   S-844 67  Sweden   \n",
            "104          1 rue Alsace-Lorraine    Toulouse      31000  France   \n",
            "105                120 Hanover Sq.      London    WA1 1DP      UK   \n",
            "106         Rambla de Catalu¤a, 23   Barcelona       8022   Spain   \n",
            "107               361 Furth Circle   San Diego      91217     USA   \n",
            "\n",
            "    CONTACTLASTNAME CONTACTFIRSTNAME DEALSIZE  \n",
            "0                Yu             Kwai    Small  \n",
            "1           Henriot             Paul    Small  \n",
            "2          Da Cunha           Daniel   Medium  \n",
            "3             Young            Julie   Medium  \n",
            "4            Hirano             Juri   Medium  \n",
            "..              ...              ...      ...  \n",
            "103         Larsson            Maria   Medium  \n",
            "104          Roulet          Annette   Medium  \n",
            "105           Hardy           Thomas   Medium  \n",
            "106        Saavedra          Eduardo   Medium  \n",
            "107        Thompson          Valarie   Medium  \n",
            "\n",
            "[108 rows x 20 columns]\n",
            "0      30\n",
            "1      40\n",
            "2      41\n",
            "3      45\n",
            "4      36\n",
            "       ..\n",
            "103    44\n",
            "104    24\n",
            "105    26\n",
            "106    45\n",
            "107    49\n",
            "Name: QUANTITYORDERED, Length: 108, dtype: int64\n",
            " How to Standardise Numeric Fields Using R/Python\n",
            "     Index  ORDERNUMBER  QUANTITYORDERED  PRICEEACH  ORDERLINENUMBER    SALES  \\\n",
            "0        0        10107        -0.631463  -1.014272                2  2871.00   \n",
            "1        1        10121         0.317049  -1.284553                5  2765.90   \n",
            "2        2        10134         0.411900  -1.032354                2  3884.34   \n",
            "3        3        10145         0.791305  -1.248578                6  3746.70   \n",
            "4        4        10168        -0.062356  -0.996191                1  3479.76   \n",
            "..     ...          ...              ...        ...              ...      ...   \n",
            "103    103        10167         0.696454  -0.280843                9  5924.16   \n",
            "104    104        10178        -1.200571  -0.075920               12  3492.48   \n",
            "105    105        10186        -1.010868  -0.024689                9  3854.24   \n",
            "106    106        10197         0.791305  -0.588228                6  5324.40   \n",
            "107    107        10222         1.170710  -0.511382               12  5997.60   \n",
            "\n",
            "     DAYS_SINCE_LASTORDER     STATUS   PRODUCTLINE  MSRP PRODUCTCODE  \\\n",
            "0                     828    Shipped   Motorcycles    95    S10_1678   \n",
            "1                     757    Shipped   Motorcycles    95    S10_1678   \n",
            "2                     703    Shipped   Motorcycles    95    S10_1678   \n",
            "3                     649    Shipped   Motorcycles    95    S10_1678   \n",
            "4                     586    Shipped   Motorcycles    95    S10_1678   \n",
            "..                    ...        ...           ...   ...         ...   \n",
            "103                   690  Cancelled  Classic Cars   136    S10_4757   \n",
            "104                   675    Shipped  Classic Cars   136    S10_4757   \n",
            "105                   670    Shipped  Classic Cars   136    S10_4757   \n",
            "106                   659    Shipped  Classic Cars   136    S10_4757   \n",
            "107                   575    Shipped  Classic Cars   136    S10_4757   \n",
            "\n",
            "                       CUSTOMERNAME             PHONE  \\\n",
            "0                 Land of Toys Inc.        2125557818   \n",
            "1                Reims Collectables        26.47.1555   \n",
            "2                   Lyon Souveniers  +33 1 46 62 7555   \n",
            "3                 Toys4GrownUps.com        6265557265   \n",
            "4              Technics Stores Inc.        6505556809   \n",
            "..                              ...               ...   \n",
            "103         Scandinavian Gift Ideas      0695-34 6555   \n",
            "104                    Alpha Cognac        61.77.6555   \n",
            "105  Double Decker Gift Stores, Ltd    (171) 555-7555   \n",
            "106              Enaco Distributors     (93) 203 4555   \n",
            "107    Collectable Mini Designs Co.        7605558146   \n",
            "\n",
            "                      ADDRESSLINE1        CITY POSTALCODE COUNTRY  \\\n",
            "0          897 Long Airport Avenue         NYC      10022     USA   \n",
            "1               59 rue de l'Abbaye       Reims      51100  France   \n",
            "2    27 rue du Colonel Pierre Avia       Paris      75508  France   \n",
            "3               78934 Hillside Dr.    Pasadena      90003     USA   \n",
            "4                9408 Furth Circle  Burlingame      94217     USA   \n",
            "..                             ...         ...        ...     ...   \n",
            "103                   ?kergatan 24       Boras   S-844 67  Sweden   \n",
            "104          1 rue Alsace-Lorraine    Toulouse      31000  France   \n",
            "105                120 Hanover Sq.      London    WA1 1DP      UK   \n",
            "106         Rambla de Catalu¤a, 23   Barcelona       8022   Spain   \n",
            "107               361 Furth Circle   San Diego      91217     USA   \n",
            "\n",
            "    CONTACTLASTNAME CONTACTFIRSTNAME DEALSIZE  \n",
            "0                Yu             Kwai    Small  \n",
            "1           Henriot             Paul    Small  \n",
            "2          Da Cunha           Daniel   Medium  \n",
            "3             Young            Julie   Medium  \n",
            "4            Hirano             Juri   Medium  \n",
            "..              ...              ...      ...  \n",
            "103         Larsson            Maria   Medium  \n",
            "104          Roulet          Annette   Medium  \n",
            "105           Hardy           Thomas   Medium  \n",
            "106        Saavedra          Eduardo   Medium  \n",
            "107        Thompson          Valarie   Medium  \n",
            "\n",
            "[108 rows x 20 columns]\n",
            "\n",
            "Summary Statistics After Standardization:\n",
            "       QUANTITYORDERED     PRICEEACH\n",
            "count     1.080000e+02  1.080000e+02\n",
            "mean      2.611080e-16 -1.819532e-16\n",
            "std       1.004662e+00  1.004662e+00\n",
            "min      -1.579976e+00 -2.159243e+00\n",
            "25%      -9.160171e-01 -7.706436e-01\n",
            "50%       2.221978e-01 -2.629502e-01\n",
            "75%       6.964540e-01  8.196300e-01\n",
            "max       2.783181e+00  1.865388e+00\n",
            "Rows with outliers:\n",
            "     Index  ORDERNUMBER  QUANTITYORDERED  PRICEEACH  ORDERLINENUMBER  \\\n",
            "0        0        10107        -0.631463  -1.014272                2   \n",
            "1        1        10121         0.317049  -1.284553                5   \n",
            "2        2        10134         0.411900  -1.032354                2   \n",
            "3        3        10145         0.791305  -1.248578                6   \n",
            "5        5        10180        -0.726315  -1.194522                9   \n",
            "6        6        10188         1.075859  -0.653773                1   \n",
            "9        9        10237        -1.295422  -0.906160                7   \n",
            "12      12        10275         0.791305  -1.068328                1   \n",
            "14      14        10299        -1.295422  -0.689748                9   \n",
            "16      16        10318         0.886157  -1.032354                1   \n",
            "19      19        10361        -1.579976  -1.450299               13   \n",
            "20      20        10375        -1.485125  -2.159243               12   \n",
            "21      21        10388         0.506752  -1.378538                4   \n",
            "22      22        10403        -1.200571  -0.906160                7   \n",
            "23      23        10417         2.783181  -0.671855                2   \n",
            "24      24        10103        -1.010868   1.098433               11   \n",
            "25      25        10112        -0.726315   1.865388                1   \n",
            "28      28        10150         0.791305   1.784586                8   \n",
            "29      29        10163        -1.485125   1.542370                1   \n",
            "30      30        10174         0.317049   1.623172                4   \n",
            "31      31        10183        -1.295422   1.582865                8   \n",
            "35      35        10228        -0.726315   1.380956                2   \n",
            "37      37        10258        -0.441761   1.703973                6   \n",
            "38      38        10270        -1.485125   1.582865                9   \n",
            "39      39        10280         0.317049   1.623172                2   \n",
            "41      41        10304         0.981008   1.259848                6   \n",
            "42      42        10312         1.075859   1.744280                3   \n",
            "47      47        10391        -1.200571  -0.920287                4   \n",
            "48      48        10411        -1.295422   0.573694                9   \n",
            "49      49        10424         2.214074   1.703973                6   \n",
            "57      57        10210        -1.295422  -0.352604                2   \n",
            "59      59        10236        -1.390273  -0.375018                1   \n",
            "62      62        10275        -1.390273  -0.330191                4   \n",
            "67      67        10329        -1.579976   0.174207                2   \n",
            "68      68        10339         0.317049  -1.518670                4   \n",
            "69      69        10361        -1.010868  -1.853365                8   \n",
            "71      71        10388         2.214074  -1.978429                5   \n",
            "74      74        10107        -0.916017   1.414482                4   \n",
            "76      76        10134        -0.536612   1.450833                4   \n",
            "78      78        10168        -1.579976   1.122541                3   \n",
            "79      79        10180         0.411900   1.268512               11   \n",
            "82      82        10223         1.170710   0.940220                3   \n",
            "85      85        10263         0.411900   1.013111                4   \n",
            "88      88        10299        -0.726315   1.523912               11   \n",
            "89      89        10308        -1.579976   1.487373                1   \n",
            "90      90        10318         0.032495   1.086190                3   \n",
            "91      91        10329        -1.010868   1.434258                3   \n",
            "92      92        10339         0.222198  -1.372700                3   \n",
            "93      93        10362        -1.390273   0.320177                4   \n",
            "94      94        10374        -1.390273   0.465959                1   \n",
            "95      95        10388        -1.485125  -1.182468                7   \n",
            "96      96        10403         2.783181   0.575389                9   \n",
            "97      97        10417         1.834669   0.283637                4   \n",
            "98      98        10105         2.214074  -0.101536                2   \n",
            "101    101        10143         1.170710  -0.665074               15   \n",
            "104    104        10178        -1.200571  -0.075920               12   \n",
            "105    105        10186        -1.010868  -0.024689                9   \n",
            "107    107        10222         1.170710  -0.511382               12   \n",
            "\n",
            "        SALES  DAYS_SINCE_LASTORDER      STATUS   PRODUCTLINE  MSRP  \\\n",
            "0     2871.00                   828     Shipped   Motorcycles    95   \n",
            "1     2765.90                   757     Shipped   Motorcycles    95   \n",
            "2     3884.34                   703     Shipped   Motorcycles    95   \n",
            "3     3746.70                   649     Shipped   Motorcycles    95   \n",
            "5     2497.77                   573     Shipped   Motorcycles    95   \n",
            "6     5512.32                   567     Shipped   Motorcycles    95   \n",
            "9     2333.12                   432     Shipped   Motorcycles    95   \n",
            "12    4177.35                   326     Shipped   Motorcycles    95   \n",
            "14    2597.39                   259     Shipped   Motorcycles    95   \n",
            "16    4358.04                   228     Shipped   Motorcycles    95   \n",
            "19    1451.00                   186     Shipped   Motorcycles    95   \n",
            "20     733.11                   139     Shipped   Motorcycles    95   \n",
            "21    3207.12                   111     Shipped   Motorcycles    95   \n",
            "22    2434.56                    76     Shipped   Motorcycles    95   \n",
            "23    7516.08                    42    Disputed   Motorcycles    95   \n",
            "24    5404.62                   878     Shipped  Classic Cars   214   \n",
            "25    7209.11                   825     Shipped  Classic Cars   214   \n",
            "28   10993.50                   649     Shipped  Classic Cars   214   \n",
            "29    4860.24                   619     Shipped  Classic Cars   214   \n",
            "30    8014.82                   603     Shipped  Classic Cars   214   \n",
            "31    5372.57                   597     Shipped  Classic Cars   214   \n",
            "35    6463.23                   484     Shipped  Classic Cars   214   \n",
            "37    7680.64                   389     Shipped  Classic Cars   214   \n",
            "38    4905.39                   356     Shipped  Classic Cars   214   \n",
            "39    8014.82                   328     Shipped  Classic Cars   214   \n",
            "41   10172.70                   275     Shipped  Classic Cars   214   \n",
            "42   11623.70                   266     Shipped  Classic Cars   214   \n",
            "47    2416.56                   131     Shipped  Classic Cars   214   \n",
            "48    4140.23                    79     Shipped  Classic Cars   214   \n",
            "49   12001.00                    50  In Process  Classic Cars   214   \n",
            "57    3009.09                   563     Shipped   Motorcycles   118   \n",
            "59    2852.08                   484     Shipped   Motorcycles   118   \n",
            "62    2904.44                   376     Shipped   Motorcycles   118   \n",
            "67    3176.00                   266     Shipped   Motorcycles   118   \n",
            "68    2756.80                   259     Shipped   Motorcycles   118   \n",
            "69    1329.90                   236     Shipped   Motorcycles   118   \n",
            "71    2225.50                   161     Shipped   Motorcycles   118   \n",
            "74    6065.55                   902     Shipped   Motorcycles   193   \n",
            "76    7023.98                   777     Shipped   Motorcycles   193   \n",
            "78    4183.00                   660     Shipped   Motorcycles   193   \n",
            "79    8892.90                   647     Shipped   Motorcycles   193   \n",
            "82    9774.03                   549     Shipped   Motorcycles   193   \n",
            "85    8336.94                   424     Shipped   Motorcycles   193   \n",
            "88    6683.34                   333     Shipped   Motorcycles   193   \n",
            "89    4570.40                   319     Shipped   Motorcycles   193   \n",
            "90    7667.14                   302     Shipped   Motorcycles   193   \n",
            "91    5868.20                   290     Shipped   Motorcycles   193   \n",
            "92    2990.13                   283     Shipped   Motorcycles   193   \n",
            "93    3664.10                   241     Shipped   Motorcycles   193   \n",
            "94    3834.38                   214     Shipped   Motorcycles   193   \n",
            "95    1822.17                   185     Shipped   Motorcycles   193   \n",
            "96   11886.60                   150     Shipped   Motorcycles   193   \n",
            "97    9218.16                   116    Disputed   Motorcycles   193   \n",
            "98    7208.00                   939     Shipped  Classic Cars   136   \n",
            "101   5597.76                   762     Shipped  Classic Cars   136   \n",
            "104   3492.48                   675     Shipped  Classic Cars   136   \n",
            "105   3854.24                   670     Shipped  Classic Cars   136   \n",
            "107   5997.60                   575     Shipped  Classic Cars   136   \n",
            "\n",
            "    PRODUCTCODE                    CUSTOMERNAME              PHONE  \\\n",
            "0      S10_1678               Land of Toys Inc.         2125557818   \n",
            "1      S10_1678              Reims Collectables         26.47.1555   \n",
            "2      S10_1678                 Lyon Souveniers   +33 1 46 62 7555   \n",
            "3      S10_1678               Toys4GrownUps.com         6265557265   \n",
            "5      S10_1678        Daedalus Designs Imports         20.16.1555   \n",
            "6      S10_1678                    Herkku Gifts     4 72 26 73 215   \n",
            "9      S10_1678                 Vitachrome Inc.         2125551500   \n",
            "12     S10_1678               La Rochelle Gifts         40.67.8555   \n",
            "14     S10_1678            Toys of Finland, Co.        90-224 8555   \n",
            "16     S10_1678           Diecast Classics Inc.         2155551555   \n",
            "19     S10_1678       Souveniers And Things Co.    61 29 49 58 555   \n",
            "20     S10_1678               La Rochelle Gifts         40.67.8555   \n",
            "21     S10_1678                FunGiftIdeas.com         5085552555   \n",
            "22     S10_1678           UK Collectables, Ltd.     (171) 555-2282   \n",
            "23     S10_1678           Euro Shopping Channel     (91) 555 94 44   \n",
            "24     S10_1949              Baane Mini Imports         07-98 9555   \n",
            "25     S10_1949        Volvo Model Replicas, Co       0921-12 3555   \n",
            "28     S10_1949         Dragon Souveniers, Ltd.       65 22 17 555   \n",
            "29     S10_1949            Classic Legends Inc.         2125558493   \n",
            "30     S10_1949     Australian Gift Network, Co     61-7-3844-6555   \n",
            "31     S10_1949         Classic Gift Ideas, Inc         2155554695   \n",
            "35     S10_1949      Cambridge Collectables Co.         6175555555   \n",
            "37     S10_1949         Tokyo Collectables, Ltd    81 33 58 40 555   \n",
            "38     S10_1949       Souveniers And Things Co.    61 29 49 58 555   \n",
            "39     S10_1949              Amica Models & Co.        011-4988555   \n",
            "41     S10_1949              Auto Assoc. & Cie.         30.59.8555   \n",
            "42     S10_1949    Mini Gifts Distributors Ltd.         4155551450   \n",
            "47     S10_1949         Anna's Decorations, Ltd       29 93 68 555   \n",
            "48     S10_1949    Quebec Home Shopping Network     (514) 555-8054   \n",
            "49     S10_1949           Euro Shopping Channel     (91) 555 94 44   \n",
            "57     S10_2016            Osaka Souveniers Co.  8 10 66 34 25 555   \n",
            "59     S10_2016    Motor Mint Distributors Inc.         2155559857   \n",
            "62     S10_2016               La Rochelle Gifts         40.67.8555   \n",
            "67     S10_2016               Land of Toys Inc.         2125557818   \n",
            "68     S10_2016         Tokyo Collectables, Ltd    81 33 58 40 555   \n",
            "69     S10_2016       Souveniers And Things Co.    61 29 49 58 555   \n",
            "71     S10_2016                FunGiftIdeas.com         5085552555   \n",
            "74     S10_4698               Land of Toys Inc.         2125557818   \n",
            "76     S10_4698                 Lyon Souveniers   +33 1 46 62 7555   \n",
            "78     S10_4698            Technics Stores Inc.         6505556809   \n",
            "79     S10_4698        Daedalus Designs Imports         20.16.1555   \n",
            "82     S10_4698      Australian Collectors, Co.       39 52 04 555   \n",
            "85     S10_4698                 Gift Depot Inc.         2035552570   \n",
            "88     S10_4698            Toys of Finland, Co.        90-224 8555   \n",
            "89     S10_4698                   Mini Classics         9145554562   \n",
            "90     S10_4698           Diecast Classics Inc.         2155551555   \n",
            "91     S10_4698               Land of Toys Inc.         2125557818   \n",
            "92     S10_4698         Tokyo Collectables, Ltd    81 33 58 40 555   \n",
            "93     S10_4698            Technics Stores Inc.         6505556809   \n",
            "94     S10_4698     Australian Gift Network, Co     61-7-3844-6555   \n",
            "95     S10_4698                FunGiftIdeas.com         5085552555   \n",
            "96     S10_4698           UK Collectables, Ltd.     (171) 555-2282   \n",
            "97     S10_4698           Euro Shopping Channel     (91) 555 94 44   \n",
            "98     S10_4757        Danish Wholesale Imports        3 11 23 555   \n",
            "101    S10_4757             Mini Creations Ltd.         5085559555   \n",
            "104    S10_4757                    Alpha Cognac         61.77.6555   \n",
            "105    S10_4757  Double Decker Gift Stores, Ltd     (171) 555-7555   \n",
            "107    S10_4757    Collectable Mini Designs Co.         7605558146   \n",
            "\n",
            "                                 ADDRESSLINE1            CITY POSTALCODE  \\\n",
            "0                     897 Long Airport Avenue             NYC      10022   \n",
            "1                          59 rue de l'Abbaye           Reims      51100   \n",
            "2               27 rue du Colonel Pierre Avia           Paris      75508   \n",
            "3                          78934 Hillside Dr.        Pasadena      90003   \n",
            "5                     184, chausse de Tournai           Lille      59000   \n",
            "6                 Drammen 121, PR 744 Sentrum          Bergen     N 5804   \n",
            "9                           2678 Kingston Rd.             NYC      10022   \n",
            "12               67, rue des Cinquante Otages          Nantes      44000   \n",
            "14                              Keskuskatu 45        Helsinki      21240   \n",
            "16                           7586 Pompton St.       Allentown      70267   \n",
            "19    Monitor Money Building, 815 Pacific Hwy       Chatswood       2067   \n",
            "20               67, rue des Cinquante Otages          Nantes      44000   \n",
            "21                          1785 First Street     New Bedford      50553   \n",
            "22               Berkeley Gardens 12  Brewery       Liverpool    WX1 6LT   \n",
            "23                         C/ Moralzarzal, 86          Madrid      28034   \n",
            "24                     Erling Skakkes gate 78         Stavern       4110   \n",
            "25                            Berguvsvgen  8            Lule   S-958 22   \n",
            "28       Bronz Sok., Bronz Apt. 3/6 Tesvikiye       Singapore      79903   \n",
            "29                           5905 Pompton St.             NYC      10022   \n",
            "30                     31 Duncan St. West End  South Brisbane       4101   \n",
            "31                           782 First Street    Philadelphia      71270   \n",
            "35                             4658 Baden Av.       Cambridge      51247   \n",
            "37                             2-2-8 Roppongi       Minato-ku   106-0032   \n",
            "38    Monitor Money Building, 815 Pacific Hwy       Chatswood       2067   \n",
            "39                        Via Monte Bianco 34          Torino      10100   \n",
            "41                     67, avenue de l'Europe      Versailles      78000   \n",
            "42                            5677 Strong St.      San Rafael      97562   \n",
            "47                          201 Miller Street    North Sydney       2060   \n",
            "48                         43 rue St. Laurent        Montreal    H1J 1C3   \n",
            "49                         C/ Moralzarzal, 86          Madrid      28034   \n",
            "57   Dojima Avanza 4F, 1-6-20 Dojima, Kita-ku           Osaka   530-0003   \n",
            "59                          11328 Douglas Av.    Philadelphia      71270   \n",
            "62               67, rue des Cinquante Otages          Nantes      44000   \n",
            "67                    897 Long Airport Avenue             NYC      10022   \n",
            "68                             2-2-8 Roppongi       Minato-ku   106-0032   \n",
            "69    Monitor Money Building, 815 Pacific Hwy       Chatswood       2067   \n",
            "71                          1785 First Street     New Bedford      50553   \n",
            "74                    897 Long Airport Avenue             NYC      10022   \n",
            "76              27 rue du Colonel Pierre Avia           Paris      75508   \n",
            "78                          9408 Furth Circle      Burlingame      94217   \n",
            "79                    184, chausse de Tournai           Lille      59000   \n",
            "82                          636 St Kilda Road       Melbourne       3004   \n",
            "85                        25593 South Bay Ln.     Bridgewater      97562   \n",
            "88                              Keskuskatu 45        Helsinki      21240   \n",
            "89                  3758 North Pendale Street    White Plains      24067   \n",
            "90                           7586 Pompton St.       Allentown      70267   \n",
            "91                    897 Long Airport Avenue             NYC      10022   \n",
            "92                             2-2-8 Roppongi       Minato-ku   106-0032   \n",
            "93                          9408 Furth Circle      Burlingame      94217   \n",
            "94                     31 Duncan St. West End  South Brisbane       4101   \n",
            "95                          1785 First Street     New Bedford      50553   \n",
            "96               Berkeley Gardens 12  Brewery       Liverpool    WX1 6LT   \n",
            "97                         C/ Moralzarzal, 86          Madrid      28034   \n",
            "98                               Vinb'ltet 34       Kobenhavn       1734   \n",
            "101                         4575 Hillside Dr.     New Bedford      50553   \n",
            "104                     1 rue Alsace-Lorraine        Toulouse      31000   \n",
            "105                           120 Hanover Sq.          London    WA1 1DP   \n",
            "107                          361 Furth Circle       San Diego      91217   \n",
            "\n",
            "       COUNTRY CONTACTLASTNAME CONTACTFIRSTNAME DEALSIZE  \n",
            "0          USA              Yu             Kwai    Small  \n",
            "1       France         Henriot             Paul    Small  \n",
            "2       France        Da Cunha           Daniel   Medium  \n",
            "3          USA           Young            Julie   Medium  \n",
            "5       France           Rance          Martine    Small  \n",
            "6       Norway          Oeztan           Veysel   Medium  \n",
            "9          USA           Frick          Michael    Small  \n",
            "12      France         Labrune           Janine   Medium  \n",
            "14     Finland       Karttunen            Matti    Small  \n",
            "16         USA              Yu            Kyung   Medium  \n",
            "19   Australia          Huxley           Adrian    Small  \n",
            "20      France         Labrune           Janine    Small  \n",
            "21         USA         Benitez          Violeta   Medium  \n",
            "22          UK           Devon        Elizabeth    Small  \n",
            "23       Spain          Freyre            Diego    Large  \n",
            "24      Norway      Bergulfsen            Jonas   Medium  \n",
            "25      Sweden        Berglund        Christina    Large  \n",
            "28   Singapore       Natividad             Eric    Large  \n",
            "29         USA       Hernandez            Maria   Medium  \n",
            "30   Australia        Calaghan             Tony    Large  \n",
            "31         USA       Cervantes        Francisca   Medium  \n",
            "35         USA           Tseng            Kyung   Medium  \n",
            "37       Japan       Shimamura            Akiko    Large  \n",
            "38   Australia          Huxley           Adrian   Medium  \n",
            "39       Italy         Accorti            Paolo    Large  \n",
            "41      France          Tonini           Daniel    Large  \n",
            "42         USA          Nelson          Valarie    Large  \n",
            "47   Australia          O'Hara             Anna    Small  \n",
            "48      Canada       Fresnisre             Jean   Medium  \n",
            "49       Spain          Freyre            Diego    Large  \n",
            "57       Japan         Kentary             Mory   Medium  \n",
            "59         USA       Hernandez             Rosa    Small  \n",
            "62      France         Labrune           Janine    Small  \n",
            "67         USA              Yu             Kwai   Medium  \n",
            "68       Japan       Shimamura            Akiko    Small  \n",
            "69   Australia          Huxley           Adrian    Small  \n",
            "71         USA         Benitez          Violeta    Small  \n",
            "74         USA              Yu             Kwai   Medium  \n",
            "76      France        Da Cunha           Daniel    Large  \n",
            "78         USA          Hirano             Juri   Medium  \n",
            "79      France           Rance          Martine    Large  \n",
            "82   Australia        Ferguson            Peter    Large  \n",
            "85         USA            King            Julie    Large  \n",
            "88     Finland       Karttunen            Matti   Medium  \n",
            "89         USA           Frick            Steve   Medium  \n",
            "90         USA              Yu            Kyung    Large  \n",
            "91         USA              Yu             Kwai   Medium  \n",
            "92       Japan       Shimamura            Akiko    Small  \n",
            "93         USA          Hirano             Juri   Medium  \n",
            "94   Australia        Calaghan             Tony   Medium  \n",
            "95         USA         Benitez          Violeta    Small  \n",
            "96          UK           Devon        Elizabeth    Large  \n",
            "97       Spain          Freyre            Diego    Large  \n",
            "98     Denmark        Petersen            Jytte    Large  \n",
            "101        USA             Tam           Wing C   Medium  \n",
            "104     France          Roulet          Annette   Medium  \n",
            "105         UK           Hardy           Thomas   Medium  \n",
            "107        USA        Thompson          Valarie   Medium  \n",
            "Rows with outliers:\n",
            "     Index  ORDERNUMBER  QUANTITYORDERED  PRICEEACH  ORDERLINENUMBER  \\\n",
            "0        0        10107        -0.631463  -1.014272                2   \n",
            "1        1        10121         0.317049  -1.284553                5   \n",
            "2        2        10134         0.411900  -1.032354                2   \n",
            "3        3        10145         0.791305  -1.248578                6   \n",
            "5        5        10180        -0.726315  -1.194522                9   \n",
            "6        6        10188         1.075859  -0.653773                1   \n",
            "9        9        10237        -1.295422  -0.906160                7   \n",
            "12      12        10275         0.791305  -1.068328                1   \n",
            "14      14        10299        -1.295422  -0.689748                9   \n",
            "16      16        10318         0.886157  -1.032354                1   \n",
            "19      19        10361        -1.579976  -1.450299               13   \n",
            "20      20        10375        -1.485125  -2.159243               12   \n",
            "21      21        10388         0.506752  -1.378538                4   \n",
            "22      22        10403        -1.200571  -0.906160                7   \n",
            "23      23        10417         2.783181  -0.671855                2   \n",
            "24      24        10103        -1.010868   1.098433               11   \n",
            "25      25        10112        -0.726315   1.865388                1   \n",
            "28      28        10150         0.791305   1.784586                8   \n",
            "29      29        10163        -1.485125   1.542370                1   \n",
            "30      30        10174         0.317049   1.623172                4   \n",
            "31      31        10183        -1.295422   1.582865                8   \n",
            "35      35        10228        -0.726315   1.380956                2   \n",
            "37      37        10258        -0.441761   1.703973                6   \n",
            "38      38        10270        -1.485125   1.582865                9   \n",
            "39      39        10280         0.317049   1.623172                2   \n",
            "41      41        10304         0.981008   1.259848                6   \n",
            "42      42        10312         1.075859   1.744280                3   \n",
            "47      47        10391        -1.200571  -0.920287                4   \n",
            "48      48        10411        -1.295422   0.573694                9   \n",
            "49      49        10424         2.214074   1.703973                6   \n",
            "57      57        10210        -1.295422  -0.352604                2   \n",
            "59      59        10236        -1.390273  -0.375018                1   \n",
            "62      62        10275        -1.390273  -0.330191                4   \n",
            "67      67        10329        -1.579976   0.174207                2   \n",
            "68      68        10339         0.317049  -1.518670                4   \n",
            "69      69        10361        -1.010868  -1.853365                8   \n",
            "71      71        10388         2.214074  -1.978429                5   \n",
            "74      74        10107        -0.916017   1.414482                4   \n",
            "76      76        10134        -0.536612   1.450833                4   \n",
            "78      78        10168        -1.579976   1.122541                3   \n",
            "79      79        10180         0.411900   1.268512               11   \n",
            "82      82        10223         1.170710   0.940220                3   \n",
            "85      85        10263         0.411900   1.013111                4   \n",
            "88      88        10299        -0.726315   1.523912               11   \n",
            "89      89        10308        -1.579976   1.487373                1   \n",
            "90      90        10318         0.032495   1.086190                3   \n",
            "91      91        10329        -1.010868   1.434258                3   \n",
            "92      92        10339         0.222198  -1.372700                3   \n",
            "93      93        10362        -1.390273   0.320177                4   \n",
            "94      94        10374        -1.390273   0.465959                1   \n",
            "95      95        10388        -1.485125  -1.182468                7   \n",
            "96      96        10403         2.783181   0.575389                9   \n",
            "97      97        10417         1.834669   0.283637                4   \n",
            "98      98        10105         2.214074  -0.101536                2   \n",
            "101    101        10143         1.170710  -0.665074               15   \n",
            "104    104        10178        -1.200571  -0.075920               12   \n",
            "105    105        10186        -1.010868  -0.024689                9   \n",
            "107    107        10222         1.170710  -0.511382               12   \n",
            "\n",
            "        SALES  DAYS_SINCE_LASTORDER      STATUS   PRODUCTLINE  MSRP  \\\n",
            "0     2871.00                   828     Shipped   Motorcycles    95   \n",
            "1     2765.90                   757     Shipped   Motorcycles    95   \n",
            "2     3884.34                   703     Shipped   Motorcycles    95   \n",
            "3     3746.70                   649     Shipped   Motorcycles    95   \n",
            "5     2497.77                   573     Shipped   Motorcycles    95   \n",
            "6     5512.32                   567     Shipped   Motorcycles    95   \n",
            "9     2333.12                   432     Shipped   Motorcycles    95   \n",
            "12    4177.35                   326     Shipped   Motorcycles    95   \n",
            "14    2597.39                   259     Shipped   Motorcycles    95   \n",
            "16    4358.04                   228     Shipped   Motorcycles    95   \n",
            "19    1451.00                   186     Shipped   Motorcycles    95   \n",
            "20     733.11                   139     Shipped   Motorcycles    95   \n",
            "21    3207.12                   111     Shipped   Motorcycles    95   \n",
            "22    2434.56                    76     Shipped   Motorcycles    95   \n",
            "23    7516.08                    42    Disputed   Motorcycles    95   \n",
            "24    5404.62                   878     Shipped  Classic Cars   214   \n",
            "25    7209.11                   825     Shipped  Classic Cars   214   \n",
            "28   10993.50                   649     Shipped  Classic Cars   214   \n",
            "29    4860.24                   619     Shipped  Classic Cars   214   \n",
            "30    8014.82                   603     Shipped  Classic Cars   214   \n",
            "31    5372.57                   597     Shipped  Classic Cars   214   \n",
            "35    6463.23                   484     Shipped  Classic Cars   214   \n",
            "37    7680.64                   389     Shipped  Classic Cars   214   \n",
            "38    4905.39                   356     Shipped  Classic Cars   214   \n",
            "39    8014.82                   328     Shipped  Classic Cars   214   \n",
            "41   10172.70                   275     Shipped  Classic Cars   214   \n",
            "42   11623.70                   266     Shipped  Classic Cars   214   \n",
            "47    2416.56                   131     Shipped  Classic Cars   214   \n",
            "48    4140.23                    79     Shipped  Classic Cars   214   \n",
            "49   12001.00                    50  In Process  Classic Cars   214   \n",
            "57    3009.09                   563     Shipped   Motorcycles   118   \n",
            "59    2852.08                   484     Shipped   Motorcycles   118   \n",
            "62    2904.44                   376     Shipped   Motorcycles   118   \n",
            "67    3176.00                   266     Shipped   Motorcycles   118   \n",
            "68    2756.80                   259     Shipped   Motorcycles   118   \n",
            "69    1329.90                   236     Shipped   Motorcycles   118   \n",
            "71    2225.50                   161     Shipped   Motorcycles   118   \n",
            "74    6065.55                   902     Shipped   Motorcycles   193   \n",
            "76    7023.98                   777     Shipped   Motorcycles   193   \n",
            "78    4183.00                   660     Shipped   Motorcycles   193   \n",
            "79    8892.90                   647     Shipped   Motorcycles   193   \n",
            "82    9774.03                   549     Shipped   Motorcycles   193   \n",
            "85    8336.94                   424     Shipped   Motorcycles   193   \n",
            "88    6683.34                   333     Shipped   Motorcycles   193   \n",
            "89    4570.40                   319     Shipped   Motorcycles   193   \n",
            "90    7667.14                   302     Shipped   Motorcycles   193   \n",
            "91    5868.20                   290     Shipped   Motorcycles   193   \n",
            "92    2990.13                   283     Shipped   Motorcycles   193   \n",
            "93    3664.10                   241     Shipped   Motorcycles   193   \n",
            "94    3834.38                   214     Shipped   Motorcycles   193   \n",
            "95    1822.17                   185     Shipped   Motorcycles   193   \n",
            "96   11886.60                   150     Shipped   Motorcycles   193   \n",
            "97    9218.16                   116    Disputed   Motorcycles   193   \n",
            "98    7208.00                   939     Shipped  Classic Cars   136   \n",
            "101   5597.76                   762     Shipped  Classic Cars   136   \n",
            "104   3492.48                   675     Shipped  Classic Cars   136   \n",
            "105   3854.24                   670     Shipped  Classic Cars   136   \n",
            "107   5997.60                   575     Shipped  Classic Cars   136   \n",
            "\n",
            "    PRODUCTCODE                    CUSTOMERNAME              PHONE  \\\n",
            "0      S10_1678               Land of Toys Inc.         2125557818   \n",
            "1      S10_1678              Reims Collectables         26.47.1555   \n",
            "2      S10_1678                 Lyon Souveniers   +33 1 46 62 7555   \n",
            "3      S10_1678               Toys4GrownUps.com         6265557265   \n",
            "5      S10_1678        Daedalus Designs Imports         20.16.1555   \n",
            "6      S10_1678                    Herkku Gifts     4 72 26 73 215   \n",
            "9      S10_1678                 Vitachrome Inc.         2125551500   \n",
            "12     S10_1678               La Rochelle Gifts         40.67.8555   \n",
            "14     S10_1678            Toys of Finland, Co.        90-224 8555   \n",
            "16     S10_1678           Diecast Classics Inc.         2155551555   \n",
            "19     S10_1678       Souveniers And Things Co.    61 29 49 58 555   \n",
            "20     S10_1678               La Rochelle Gifts         40.67.8555   \n",
            "21     S10_1678                FunGiftIdeas.com         5085552555   \n",
            "22     S10_1678           UK Collectables, Ltd.     (171) 555-2282   \n",
            "23     S10_1678           Euro Shopping Channel     (91) 555 94 44   \n",
            "24     S10_1949              Baane Mini Imports         07-98 9555   \n",
            "25     S10_1949        Volvo Model Replicas, Co       0921-12 3555   \n",
            "28     S10_1949         Dragon Souveniers, Ltd.       65 22 17 555   \n",
            "29     S10_1949            Classic Legends Inc.         2125558493   \n",
            "30     S10_1949     Australian Gift Network, Co     61-7-3844-6555   \n",
            "31     S10_1949         Classic Gift Ideas, Inc         2155554695   \n",
            "35     S10_1949      Cambridge Collectables Co.         6175555555   \n",
            "37     S10_1949         Tokyo Collectables, Ltd    81 33 58 40 555   \n",
            "38     S10_1949       Souveniers And Things Co.    61 29 49 58 555   \n",
            "39     S10_1949              Amica Models & Co.        011-4988555   \n",
            "41     S10_1949              Auto Assoc. & Cie.         30.59.8555   \n",
            "42     S10_1949    Mini Gifts Distributors Ltd.         4155551450   \n",
            "47     S10_1949         Anna's Decorations, Ltd       29 93 68 555   \n",
            "48     S10_1949    Quebec Home Shopping Network     (514) 555-8054   \n",
            "49     S10_1949           Euro Shopping Channel     (91) 555 94 44   \n",
            "57     S10_2016            Osaka Souveniers Co.  8 10 66 34 25 555   \n",
            "59     S10_2016    Motor Mint Distributors Inc.         2155559857   \n",
            "62     S10_2016               La Rochelle Gifts         40.67.8555   \n",
            "67     S10_2016               Land of Toys Inc.         2125557818   \n",
            "68     S10_2016         Tokyo Collectables, Ltd    81 33 58 40 555   \n",
            "69     S10_2016       Souveniers And Things Co.    61 29 49 58 555   \n",
            "71     S10_2016                FunGiftIdeas.com         5085552555   \n",
            "74     S10_4698               Land of Toys Inc.         2125557818   \n",
            "76     S10_4698                 Lyon Souveniers   +33 1 46 62 7555   \n",
            "78     S10_4698            Technics Stores Inc.         6505556809   \n",
            "79     S10_4698        Daedalus Designs Imports         20.16.1555   \n",
            "82     S10_4698      Australian Collectors, Co.       39 52 04 555   \n",
            "85     S10_4698                 Gift Depot Inc.         2035552570   \n",
            "88     S10_4698            Toys of Finland, Co.        90-224 8555   \n",
            "89     S10_4698                   Mini Classics         9145554562   \n",
            "90     S10_4698           Diecast Classics Inc.         2155551555   \n",
            "91     S10_4698               Land of Toys Inc.         2125557818   \n",
            "92     S10_4698         Tokyo Collectables, Ltd    81 33 58 40 555   \n",
            "93     S10_4698            Technics Stores Inc.         6505556809   \n",
            "94     S10_4698     Australian Gift Network, Co     61-7-3844-6555   \n",
            "95     S10_4698                FunGiftIdeas.com         5085552555   \n",
            "96     S10_4698           UK Collectables, Ltd.     (171) 555-2282   \n",
            "97     S10_4698           Euro Shopping Channel     (91) 555 94 44   \n",
            "98     S10_4757        Danish Wholesale Imports        3 11 23 555   \n",
            "101    S10_4757             Mini Creations Ltd.         5085559555   \n",
            "104    S10_4757                    Alpha Cognac         61.77.6555   \n",
            "105    S10_4757  Double Decker Gift Stores, Ltd     (171) 555-7555   \n",
            "107    S10_4757    Collectable Mini Designs Co.         7605558146   \n",
            "\n",
            "                                 ADDRESSLINE1            CITY POSTALCODE  \\\n",
            "0                     897 Long Airport Avenue             NYC      10022   \n",
            "1                          59 rue de l'Abbaye           Reims      51100   \n",
            "2               27 rue du Colonel Pierre Avia           Paris      75508   \n",
            "3                          78934 Hillside Dr.        Pasadena      90003   \n",
            "5                     184, chausse de Tournai           Lille      59000   \n",
            "6                 Drammen 121, PR 744 Sentrum          Bergen     N 5804   \n",
            "9                           2678 Kingston Rd.             NYC      10022   \n",
            "12               67, rue des Cinquante Otages          Nantes      44000   \n",
            "14                              Keskuskatu 45        Helsinki      21240   \n",
            "16                           7586 Pompton St.       Allentown      70267   \n",
            "19    Monitor Money Building, 815 Pacific Hwy       Chatswood       2067   \n",
            "20               67, rue des Cinquante Otages          Nantes      44000   \n",
            "21                          1785 First Street     New Bedford      50553   \n",
            "22               Berkeley Gardens 12  Brewery       Liverpool    WX1 6LT   \n",
            "23                         C/ Moralzarzal, 86          Madrid      28034   \n",
            "24                     Erling Skakkes gate 78         Stavern       4110   \n",
            "25                            Berguvsvgen  8            Lule   S-958 22   \n",
            "28       Bronz Sok., Bronz Apt. 3/6 Tesvikiye       Singapore      79903   \n",
            "29                           5905 Pompton St.             NYC      10022   \n",
            "30                     31 Duncan St. West End  South Brisbane       4101   \n",
            "31                           782 First Street    Philadelphia      71270   \n",
            "35                             4658 Baden Av.       Cambridge      51247   \n",
            "37                             2-2-8 Roppongi       Minato-ku   106-0032   \n",
            "38    Monitor Money Building, 815 Pacific Hwy       Chatswood       2067   \n",
            "39                        Via Monte Bianco 34          Torino      10100   \n",
            "41                     67, avenue de l'Europe      Versailles      78000   \n",
            "42                            5677 Strong St.      San Rafael      97562   \n",
            "47                          201 Miller Street    North Sydney       2060   \n",
            "48                         43 rue St. Laurent        Montreal    H1J 1C3   \n",
            "49                         C/ Moralzarzal, 86          Madrid      28034   \n",
            "57   Dojima Avanza 4F, 1-6-20 Dojima, Kita-ku           Osaka   530-0003   \n",
            "59                          11328 Douglas Av.    Philadelphia      71270   \n",
            "62               67, rue des Cinquante Otages          Nantes      44000   \n",
            "67                    897 Long Airport Avenue             NYC      10022   \n",
            "68                             2-2-8 Roppongi       Minato-ku   106-0032   \n",
            "69    Monitor Money Building, 815 Pacific Hwy       Chatswood       2067   \n",
            "71                          1785 First Street     New Bedford      50553   \n",
            "74                    897 Long Airport Avenue             NYC      10022   \n",
            "76              27 rue du Colonel Pierre Avia           Paris      75508   \n",
            "78                          9408 Furth Circle      Burlingame      94217   \n",
            "79                    184, chausse de Tournai           Lille      59000   \n",
            "82                          636 St Kilda Road       Melbourne       3004   \n",
            "85                        25593 South Bay Ln.     Bridgewater      97562   \n",
            "88                              Keskuskatu 45        Helsinki      21240   \n",
            "89                  3758 North Pendale Street    White Plains      24067   \n",
            "90                           7586 Pompton St.       Allentown      70267   \n",
            "91                    897 Long Airport Avenue             NYC      10022   \n",
            "92                             2-2-8 Roppongi       Minato-ku   106-0032   \n",
            "93                          9408 Furth Circle      Burlingame      94217   \n",
            "94                     31 Duncan St. West End  South Brisbane       4101   \n",
            "95                          1785 First Street     New Bedford      50553   \n",
            "96               Berkeley Gardens 12  Brewery       Liverpool    WX1 6LT   \n",
            "97                         C/ Moralzarzal, 86          Madrid      28034   \n",
            "98                               Vinb'ltet 34       Kobenhavn       1734   \n",
            "101                         4575 Hillside Dr.     New Bedford      50553   \n",
            "104                     1 rue Alsace-Lorraine        Toulouse      31000   \n",
            "105                           120 Hanover Sq.          London    WA1 1DP   \n",
            "107                          361 Furth Circle       San Diego      91217   \n",
            "\n",
            "       COUNTRY CONTACTLASTNAME CONTACTFIRSTNAME DEALSIZE  \n",
            "0          USA              Yu             Kwai    Small  \n",
            "1       France         Henriot             Paul    Small  \n",
            "2       France        Da Cunha           Daniel   Medium  \n",
            "3          USA           Young            Julie   Medium  \n",
            "5       France           Rance          Martine    Small  \n",
            "6       Norway          Oeztan           Veysel   Medium  \n",
            "9          USA           Frick          Michael    Small  \n",
            "12      France         Labrune           Janine   Medium  \n",
            "14     Finland       Karttunen            Matti    Small  \n",
            "16         USA              Yu            Kyung   Medium  \n",
            "19   Australia          Huxley           Adrian    Small  \n",
            "20      France         Labrune           Janine    Small  \n",
            "21         USA         Benitez          Violeta   Medium  \n",
            "22          UK           Devon        Elizabeth    Small  \n",
            "23       Spain          Freyre            Diego    Large  \n",
            "24      Norway      Bergulfsen            Jonas   Medium  \n",
            "25      Sweden        Berglund        Christina    Large  \n",
            "28   Singapore       Natividad             Eric    Large  \n",
            "29         USA       Hernandez            Maria   Medium  \n",
            "30   Australia        Calaghan             Tony    Large  \n",
            "31         USA       Cervantes        Francisca   Medium  \n",
            "35         USA           Tseng            Kyung   Medium  \n",
            "37       Japan       Shimamura            Akiko    Large  \n",
            "38   Australia          Huxley           Adrian   Medium  \n",
            "39       Italy         Accorti            Paolo    Large  \n",
            "41      France          Tonini           Daniel    Large  \n",
            "42         USA          Nelson          Valarie    Large  \n",
            "47   Australia          O'Hara             Anna    Small  \n",
            "48      Canada       Fresnisre             Jean   Medium  \n",
            "49       Spain          Freyre            Diego    Large  \n",
            "57       Japan         Kentary             Mory   Medium  \n",
            "59         USA       Hernandez             Rosa    Small  \n",
            "62      France         Labrune           Janine    Small  \n",
            "67         USA              Yu             Kwai   Medium  \n",
            "68       Japan       Shimamura            Akiko    Small  \n",
            "69   Australia          Huxley           Adrian    Small  \n",
            "71         USA         Benitez          Violeta    Small  \n",
            "74         USA              Yu             Kwai   Medium  \n",
            "76      France        Da Cunha           Daniel    Large  \n",
            "78         USA          Hirano             Juri   Medium  \n",
            "79      France           Rance          Martine    Large  \n",
            "82   Australia        Ferguson            Peter    Large  \n",
            "85         USA            King            Julie    Large  \n",
            "88     Finland       Karttunen            Matti   Medium  \n",
            "89         USA           Frick            Steve   Medium  \n",
            "90         USA              Yu            Kyung    Large  \n",
            "91         USA              Yu             Kwai   Medium  \n",
            "92       Japan       Shimamura            Akiko    Small  \n",
            "93         USA          Hirano             Juri   Medium  \n",
            "94   Australia        Calaghan             Tony   Medium  \n",
            "95         USA         Benitez          Violeta    Small  \n",
            "96          UK           Devon        Elizabeth    Large  \n",
            "97       Spain          Freyre            Diego    Large  \n",
            "98     Denmark        Petersen            Jytte    Large  \n",
            "101        USA             Tam           Wing C   Medium  \n",
            "104     France          Roulet          Annette   Medium  \n",
            "105         UK           Hardy           Thomas   Medium  \n",
            "107        USA        Thompson          Valarie   Medium  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#3: EXPLORATORY DATA ANALYSIS\n"
      ],
      "metadata": {
        "id": "TkzB-KoBQyAU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# 1 How to Construct a Bar Graph with Overlay Using Python\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Assuming 'QUANTITYORDERED' and 'PRICEEACH' are columns in your dataset\n",
        "a = data.index  # Assuming 'a' corresponds to the index of your DataFrame\n",
        "b = data['QUANTITYORDERED']\n",
        "c = data['PRICEEACH']\n",
        "\n",
        "# Create a DataFrame\n",
        "df_custom = pd.DataFrame({'a': a, 'b': b, 'c': c}, columns=['a', 'b', 'c'])\n",
        "df_custom.set_index('a', inplace=True)\n",
        "\n",
        "# Plotting\n",
        "df_custom.plot.bar()\n",
        "plt.title('Bar Graph with Overlay')\n",
        "plt.xlabel('DEALSIZE')\n",
        "plt.ylabel('Values')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# 3  How to Construct Histograms with Overlay Using R/Python\n",
        "\n",
        "# Plot histograms with overlay\n",
        "plt.figure(figsize=(10, 6))\n",
        "\n",
        "# Histogram for 'QUANTITYORDERED'\n",
        "plt.hist(data['QUANTITYORDERED'], bins=20, alpha=0.5, label='QUANTITYORDERED')\n",
        "\n",
        "# Histogram for 'PRICEEACH'\n",
        "plt.hist(data['PRICEEACH'], bins=20, alpha=0.5, label='PRICEEACH')\n",
        "\n",
        "# Set labels and title\n",
        "plt.xlabel('Values')\n",
        "plt.ylabel('Frequency')\n",
        "plt.title('Histograms with Overlay')\n",
        "plt.legend()\n",
        "\n",
        "# Show the plot\n",
        "plt.show()\n",
        "\n",
        "\n",
        "# 4  How to Perform Binning Based on Predictive Value Using R/Python\n",
        "\n",
        "import pandas as pd\n",
        "from sklearn.preprocessing import KBinsDiscretizer\n",
        "\n",
        "\n",
        "# Specify the features you want to use for binning\n",
        "features_for_binning = ['QUANTITYORDERED', 'PRICEEACH', 'SALES']\n",
        "\n",
        "# Specify the target variable\n",
        "target_variable = 'PRODUCTLINE'\n",
        "\n",
        "# Extract features and target variable\n",
        "X = data[features_for_binning]\n",
        "y = data[target_variable]\n",
        "\n",
        "# Initialize KBinsDiscretizer\n",
        "k_bins_discretizer = KBinsDiscretizer(n_bins=5, encode='ordinal', strategy='quantile')\n",
        "\n",
        "# Fit and transform the features\n",
        "X_binned = k_bins_discretizer.fit_transform(X)\n",
        "\n",
        "# Create a new DataFrame with the binned features\n",
        "df_binned = pd.DataFrame(X_binned, columns=[f'{feature}_binned' for feature in features_for_binning])\n",
        "\n",
        "# Concatenate the binned features with the original DataFrame\n",
        "data = pd.concat([data, df_binned], axis=1)\n",
        "\n",
        "# Print the updated DataFrame\n",
        "print(data)\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "ukAYlTgxQ0vM",
        "outputId": "464606e7-4c3c-485a-c5ea-bca83ca993dd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x600 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     Index  ORDERNUMBER  QUANTITYORDERED  PRICEEACH  ORDERLINENUMBER    SALES  \\\n",
            "0        0        10107        -0.631463  -1.014272                2  2871.00   \n",
            "1        1        10121         0.317049  -1.284553                5  2765.90   \n",
            "2        2        10134         0.411900  -1.032354                2  3884.34   \n",
            "3        3        10145         0.791305  -1.248578                6  3746.70   \n",
            "4        4        10168        -0.062356  -0.996191                1  3479.76   \n",
            "..     ...          ...              ...        ...              ...      ...   \n",
            "103    103        10167         0.696454  -0.280843                9  5924.16   \n",
            "104    104        10178        -1.200571  -0.075920               12  3492.48   \n",
            "105    105        10186        -1.010868  -0.024689                9  3854.24   \n",
            "106    106        10197         0.791305  -0.588228                6  5324.40   \n",
            "107    107        10222         1.170710  -0.511382               12  5997.60   \n",
            "\n",
            "     DAYS_SINCE_LASTORDER     STATUS   PRODUCTLINE  MSRP  ...  \\\n",
            "0                     828    Shipped   Motorcycles    95  ...   \n",
            "1                     757    Shipped   Motorcycles    95  ...   \n",
            "2                     703    Shipped   Motorcycles    95  ...   \n",
            "3                     649    Shipped   Motorcycles    95  ...   \n",
            "4                     586    Shipped   Motorcycles    95  ...   \n",
            "..                    ...        ...           ...   ...  ...   \n",
            "103                   690  Cancelled  Classic Cars   136  ...   \n",
            "104                   675    Shipped  Classic Cars   136  ...   \n",
            "105                   670    Shipped  Classic Cars   136  ...   \n",
            "106                   659    Shipped  Classic Cars   136  ...   \n",
            "107                   575    Shipped  Classic Cars   136  ...   \n",
            "\n",
            "                      ADDRESSLINE1        CITY POSTALCODE COUNTRY  \\\n",
            "0          897 Long Airport Avenue         NYC      10022     USA   \n",
            "1               59 rue de l'Abbaye       Reims      51100  France   \n",
            "2    27 rue du Colonel Pierre Avia       Paris      75508  France   \n",
            "3               78934 Hillside Dr.    Pasadena      90003     USA   \n",
            "4                9408 Furth Circle  Burlingame      94217     USA   \n",
            "..                             ...         ...        ...     ...   \n",
            "103                   ?kergatan 24       Boras   S-844 67  Sweden   \n",
            "104          1 rue Alsace-Lorraine    Toulouse      31000  France   \n",
            "105                120 Hanover Sq.      London    WA1 1DP      UK   \n",
            "106         Rambla de Catalu¤a, 23   Barcelona       8022   Spain   \n",
            "107               361 Furth Circle   San Diego      91217     USA   \n",
            "\n",
            "    CONTACTLASTNAME CONTACTFIRSTNAME DEALSIZE QUANTITYORDERED_binned  \\\n",
            "0                Yu             Kwai    Small                    1.0   \n",
            "1           Henriot             Paul    Small                    3.0   \n",
            "2          Da Cunha           Daniel   Medium                    3.0   \n",
            "3             Young            Julie   Medium                    4.0   \n",
            "4            Hirano             Juri   Medium                    2.0   \n",
            "..              ...              ...      ...                    ...   \n",
            "103         Larsson            Maria   Medium                    3.0   \n",
            "104          Roulet          Annette   Medium                    0.0   \n",
            "105           Hardy           Thomas   Medium                    1.0   \n",
            "106        Saavedra          Eduardo   Medium                    4.0   \n",
            "107        Thompson          Valarie   Medium                    4.0   \n",
            "\n",
            "    PRICEEACH_binned SALES_binned  \n",
            "0                0.0          0.0  \n",
            "1                0.0          0.0  \n",
            "2                0.0          1.0  \n",
            "3                0.0          1.0  \n",
            "4                0.0          1.0  \n",
            "..               ...          ...  \n",
            "103              2.0          3.0  \n",
            "104              2.0          1.0  \n",
            "105              2.0          1.0  \n",
            "106              1.0          2.0  \n",
            "107              1.0          3.0  \n",
            "\n",
            "[108 rows x 23 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#4:    DATA PREPARATION PHASE TO MODEL THE DATA"
      ],
      "metadata": {
        "id": "Gd662jnH8WGp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "\n",
        "#How to Build CART Decision Trees Using Python\n",
        "\n",
        "\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
        "\n",
        "# Initialize the Decision Tree classifier\n",
        "tree_classifier = DecisionTreeClassifier(random_state=10)\n",
        "\n",
        "# Fit the model on the resampled training set\n",
        "tree_classifier.fit(X_resampled, y_resampled)\n",
        "\n",
        "# Make predictions on the testing set\n",
        "y_pred = tree_classifier.predict(X_test)\n",
        "\n",
        "# Evaluate the performance of the Decision Tree model\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "conf_matrix = confusion_matrix(y_test, y_pred)\n",
        "class_report = classification_report(y_test, y_pred)\n",
        "\n",
        "# Print the results\n",
        "print(f\"Accuracy: {accuracy:.2f}\")\n",
        "print(\"\\nConfusion Matrix:\")\n",
        "print(conf_matrix)\n",
        "print(\"\\nClassification Report:\")\n",
        "print(class_report)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 245
        },
        "id": "a6ytXJC48XzX",
        "outputId": "6f3acf5d-bc41-4fb1-870d-58e9a82c2731"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-5-7e1ab133bc23>\u001b[0m in \u001b[0;36m<cell line: 11>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;31m# Fit the model on the resampled training set\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0mtree_classifier\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_resampled\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_resampled\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;31m# Make predictions on the testing set\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'X_resampled' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#5: MODEL EVALUATION\n",
        "\n"
      ],
      "metadata": {
        "id": "v6Rkil0SEMmz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#5: MODEL EVALUATION\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn import metrics\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.linear_model import LogisticRegression, SGDClassifier\n",
        "from sklearn.model_selection import train_test_split, cross_val_score, cross_val_predict, StratifiedKFold\n",
        "sns.set()\n",
        "\n",
        "df = pd.read_csv(\"/content/drive/MyDrive/dataset/Auto Sales data.csv\")\n",
        "\n",
        "#print(df.info())\n",
        "#print(df.head())\n",
        "#print(df.describe())\n",
        "#df.shape\n",
        "#print(df.isna().sum())\n",
        "#var = 'target'\n",
        "#ns.countplot(df[var])\n",
        "#var = 'age'\n",
        "#f, ax = plt.subplots(figsize=(15,8))\n",
        "#sns.distplot(df[var])\n",
        "#plt.xlim([0,80])\n",
        "#var = 'chol'\n",
        "#f, ax = plt.subplots(figsize=(15,8))\n",
        "#sns.distplot(df[var])\n",
        "#plt.xlim([0,600])\n",
        "#var = 'trestbps'\n",
        "#f, ax = plt.subplots(figsize=(15,8))\n",
        "#sns.distplot(df[var])\n",
        "#plt.xlim([0,250])\n",
        "df.columns\n",
        "X = df.iloc[:,:-1]\n",
        "y = df.iloc[:,-1]\n",
        "print(\"\\n\\n\\t\\tIndependent features of Dataset: \")\n",
        "print(X.head())\n",
        "print(\"\\n\\n\\t\\tDependent features of Dataset: \")\n",
        "print(y.head())\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state = 25)\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "scaler = StandardScaler()\n",
        "\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)\n",
        "log_reg = LogisticRegression()\n",
        "log_reg.fit(X_train, y_train)\n",
        "y_pred = log_reg.predict(X_test)\n",
        "\n",
        "print(\"Classification Model Accuracy is: \",metrics.accuracy_score(y_test, y_pred))\n",
        "import scikitplot as skplt\n",
        "#skplt.metrics.plot_confusion_matrix(y_test,y_pred)\n",
        "\n",
        "from sklearn.metrics import average_precision_score\n",
        "from sklearn.metrics import precision_recall_curve\n",
        "\n",
        "average_precision = average_precision_score(y_test, y_pred)\n",
        "print('Average precision-recall score: {0:0.2f}'.format(average_precision))\n",
        "\n",
        "from sklearn.metrics import f1_score\n",
        "print(\"Macro F1 Score: \",f1_score(y_test, y_pred, average='macro'))\n",
        "print(\"Micro F1 Score: \",f1_score(y_test, y_pred, average='micro'))\n",
        "print(\"Weighted F1 Score: \",f1_score(y_test, y_pred, average='weighted'))\n",
        "fpr, tpr, thresholds = metrics.roc_curve(y_test, y_pred)\n",
        "\n",
        "plt.plot(fpr, tpr)\n",
        "plt.title('ROC curve for Heart Attack classifier')\n",
        "plt.xlabel('False Positive Rate (1 - Specificity)')\n",
        "plt.ylabel('True Positive Rate (Sensitivity)')\n",
        "plt.grid(True)\n",
        "\n",
        "from sklearn.metrics import classification_report\n",
        "target_names = ['class 0', 'class 1']\n",
        "print(classification_report(y_test, y_pred, target_names=target_names))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "BeTuB6bAES6a",
        "outputId": "d24d5555-b201-4495-efc4-e7945735e5e0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\t\tIndependent features of Dataset: \n",
            "   ORDERNUMBER  QUANTITYORDERED  PRICEEACH  ORDERLINENUMBER    SALES  \\\n",
            "0        10107               30      95.70                2  2871.00   \n",
            "1        10121               34      81.35                5  2765.90   \n",
            "2        10134               41      94.74                2  3884.34   \n",
            "3        10145               45      83.26                6  3746.70   \n",
            "4        10168               36      96.66                1  3479.76   \n",
            "\n",
            "   DAYS_SINCE_LASTORDER   STATUS  PRODUCTLINE  MSRP PRODUCTCODE  \\\n",
            "0                   828  Shipped  Motorcycles    95    S10_1678   \n",
            "1                   757  Shipped  Motorcycles    95    S10_1678   \n",
            "2                   703  Shipped  Motorcycles    95    S10_1678   \n",
            "3                   649  Shipped  Motorcycles    95    S10_1678   \n",
            "4                   586  Shipped  Motorcycles    95    S10_1678   \n",
            "\n",
            "           CUSTOMERNAME             PHONE                   ADDRESSLINE1  \\\n",
            "0     Land of Toys Inc.        2125557818        897 Long Airport Avenue   \n",
            "1    Reims Collectables        26.47.1555             59 rue de l'Abbaye   \n",
            "2       Lyon Souveniers  +33 1 46 62 7555  27 rue du Colonel Pierre Avia   \n",
            "3     Toys4GrownUps.com        6265557265             78934 Hillside Dr.   \n",
            "4  Technics Stores Inc.        6505556809              9408 Furth Circle   \n",
            "\n",
            "         CITY POSTALCODE COUNTRY CONTACTLASTNAME CONTACTFIRSTNAME  \n",
            "0         NYC      10022     USA              Yu             Kwai  \n",
            "1       Reims      51100  France         Henriot             Paul  \n",
            "2       Paris      75508  France        Da Cunha           Daniel  \n",
            "3    Pasadena      90003     USA           Young            Julie  \n",
            "4  Burlingame      94217     USA          Hirano             Juri  \n",
            "\n",
            "\n",
            "\t\tDependent features of Dataset: \n",
            "0     Small\n",
            "1     Small\n",
            "2    Medium\n",
            "3    Medium\n",
            "4    Medium\n",
            "Name: DEALSIZE, dtype: object\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-6-b9e5ec400f55>\u001b[0m in \u001b[0;36m<cell line: 44>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[0mscaler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mStandardScaler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m \u001b[0mX_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscaler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m \u001b[0mX_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscaler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[0mlog_reg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLogisticRegression\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/utils/_set_output.py\u001b[0m in \u001b[0;36mwrapped\u001b[0;34m(self, X, *args, **kwargs)\u001b[0m\n\u001b[1;32m    138\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mwraps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    139\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mwrapped\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 140\u001b[0;31m         \u001b[0mdata_to_wrap\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    141\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_to_wrap\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    142\u001b[0m             \u001b[0;31m# only wrap the first output for cross decomposition\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/base.py\u001b[0m in \u001b[0;36mfit_transform\u001b[0;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[1;32m    876\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0my\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    877\u001b[0m             \u001b[0;31m# fit method of arity 1 (unsupervised transformation)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 878\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    879\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    880\u001b[0m             \u001b[0;31m# fit method of arity 2 (supervised transformation)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/preprocessing/_data.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    822\u001b[0m         \u001b[0;31m# Reset internal state before fitting\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    823\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 824\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpartial_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    825\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    826\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mpartial_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/preprocessing/_data.py\u001b[0m in \u001b[0;36mpartial_fit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    859\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    860\u001b[0m         \u001b[0mfirst_call\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"n_samples_seen_\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 861\u001b[0;31m         X = self._validate_data(\n\u001b[0m\u001b[1;32m    862\u001b[0m             \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    863\u001b[0m             \u001b[0maccept_sparse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"csr\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"csc\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/base.py\u001b[0m in \u001b[0;36m_validate_data\u001b[0;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[1;32m    563\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Validation should be done on X, y or both.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    564\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mno_val_X\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mno_val_y\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 565\u001b[0;31m             \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"X\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mcheck_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    566\u001b[0m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    567\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mno_val_X\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mno_val_y\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[1;32m    877\u001b[0m                     \u001b[0marray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mxp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    878\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 879\u001b[0;31m                     \u001b[0marray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_asarray_with_order\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mxp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    880\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mComplexWarning\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mcomplex_warning\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    881\u001b[0m                 raise ValueError(\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/utils/_array_api.py\u001b[0m in \u001b[0;36m_asarray_with_order\u001b[0;34m(array, dtype, order, copy, xp)\u001b[0m\n\u001b[1;32m    183\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mxp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m\"numpy\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"numpy.array_api\"\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    184\u001b[0m         \u001b[0;31m# Use NumPy API to support order\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 185\u001b[0;31m         \u001b[0marray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    186\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mxp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m__array__\u001b[0;34m(self, dtype)\u001b[0m\n\u001b[1;32m   2068\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2069\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__array__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mnpt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDTypeLike\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2070\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_values\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2071\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2072\u001b[0m     def __array_wrap__(\n",
            "\u001b[0;31mValueError\u001b[0m: could not convert string to float: 'Shipped'"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#6: NAÏVE BAYES CLASSIFICATION\n"
      ],
      "metadata": {
        "id": "yUlh1DAVFzoT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Demonstrate application of Naïve Bayes\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn import metrics\n",
        "import category_encoders as ce\n",
        "from sklearn.preprocessing import RobustScaler\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "\n",
        "data = '/content/drive/MyDrive/dataset/Auto Sales data.csv'\n",
        "\n",
        "df = pd.read_csv(data)\n",
        "\n",
        "#df.head()\n",
        "#df.shape\n",
        "#df.info()\n",
        "categorical = [var for var in df.columns if df[var].dtype=='O']\n",
        "\n",
        "#print('There are {} categorical variables\\n'.format(len(categorical)))\n",
        "\n",
        "#print('The categorical variables are :\\n\\n', categorical)\n",
        "\n",
        "#df[categorical].isnull().sum()\n",
        "#df.workclass.unique()\n",
        "\n",
        "#for var in categorical:\n",
        "\n",
        "    #print(df[var].value_counts())\n",
        "\n",
        "#for var in categorical:\n",
        "\n",
        "  #print(df[var].value_counts()/np.float(len(df)))\n",
        "\n",
        "#for var in categorical:\n",
        "\n",
        "    #print(var, ' contains ', len(df[var].unique()), ' labels')\n",
        "\n",
        "numerical = [var for var in df.columns if df[var].dtype!='O']\n",
        "\n",
        "#print('There are {} numerical variables\\n'.format(len(numerical)))\n",
        "\n",
        "#print('The numerical variables are :', numerical)\n",
        "\n",
        "#df[numerical].head()\n",
        "\n",
        "X = df.drop(['Salary'], axis=1)\n",
        "\n",
        "y = df['Salary']\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state = 0)\n",
        "\n",
        "X_train.shape, X_test.shape\n",
        "\n",
        "X_train.dtypes\n",
        "\n",
        "#categorical = [col for col in X_train.columns if X_train[col].dtypes == 'O']\n",
        "\n",
        "categorical\n",
        "\n",
        "#numerical = [col for col in X_train.columns if X_train[col].dtypes != 'O']\n",
        "\n",
        "#numerical\n",
        "\n",
        "#X_train.isnull().sum()\n",
        "\n",
        "#X_test.isnull().sum()\n",
        "encoder = ce.OneHotEncoder(cols=['Gender', 'Job Title', 'Country', 'Race'])\n",
        "\n",
        "X_train = encoder.fit_transform(X_train)\n",
        "\n",
        "X_test = encoder.transform(X_test)\n",
        "X_train.head()\n",
        "\n",
        "X_train.shape\n",
        "\n",
        "X_test.head()\n",
        "\n",
        "cols = X_train.columns\n",
        "\n",
        "scaler = RobustScaler()\n",
        "\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "\n",
        "X_test = scaler.transform(X_test)\n",
        "\n",
        "X_train = pd.DataFrame(X_train, columns=[cols])\n",
        "\n",
        "X_test = pd.DataFrame(X_test, columns=[cols])\n",
        "\n",
        "# instantiate the model\n",
        "gnb = GaussianNB()\n",
        "\n",
        "# fit the model\n",
        "gnb.fit(X_train, y_train)\n",
        "\n",
        "y_pred = gnb.predict(X_test)\n",
        "\n",
        "y_pred\n",
        "\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "print('Model accuracy score: {0:0.4f}'. format(accuracy_score(y_test, y_pred)))\n",
        "\n",
        "y_pred_train = gnb.predict(X_train)\n",
        "\n",
        "y_pred_train\n",
        "\n",
        "print('Training-set accuracy score: {0:0.4f}'. format(accuracy_score(y_train, y_pred_train)))\n",
        "\n",
        "y_test.value_counts()\n",
        "\n",
        "null_accuracy = (7407/(7407+2362))\n",
        "\n",
        "print('Null accuracy score: {0:0.4f}'. format(null_accuracy))"
      ],
      "metadata": {
        "id": "p5V_xBr5GAZX",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 384
        },
        "outputId": "de5d4604-94a0-4005-b3f3-1b1fc16a3af5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-7-b13c3f6a6957>\u001b[0m in \u001b[0;36m<cell line: 9>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtree\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mDecisionTreeClassifier\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mcategory_encoders\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mce\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpreprocessing\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mRobustScaler\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnaive_bayes\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mGaussianNB\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'category_encoders'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#7: NEURAL NETWORKS\n"
      ],
      "metadata": {
        "id": "SHnLcHGHG_9j"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn import model_selection, preprocessing, metrics\n",
        "from sklearn.preprocessing import LabelEncoder, OneHotEncoder, StandardScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "\n",
        "data = '/content/drive/MyDrive/dataset/Auto Sales data.csv'\n",
        "\n",
        "df = pd.read_csv(data)\n",
        "df.head(5)\n",
        "\n",
        "col_names = df.columns\n",
        "for c in col_names:\n",
        "\tdf[c] = df[c].replace(\"?\", np.NaN)\n",
        "\n",
        "df = df.apply(lambda x:x.fillna(x.value_counts().index[0]))\n",
        "\n",
        "df.replace(['Divorced', 'Married-AF-spouse', 'Married-civ-spouse', 'Married-spouse-absent','Never-married','Separated','Widowed'],\n",
        "             ['divorced','married','married','married','not married','not married','not married'], inplace = True)\n",
        "\n",
        "labelEncoder = preprocessing.LabelEncoder()\n",
        "category_col =['race','marital-status', 'gender', 'income']\n",
        "\n",
        "for col in category_col:\n",
        "    df[col] = labelEncoder.fit_transform(df[col])\n",
        "\n",
        "category_col_1 =['workclass', 'education', 'occupation',\n",
        "               'relationship','native-country']\n",
        "df_2 = pd.get_dummies(df, columns=category_col_1, drop_first=True)\n",
        "\n",
        "##unknown Attribute is removed and income class label is appended in the end\n",
        "dataframe=df_2.drop('fnlwgt',1)\n",
        "dataframe =dataframe[[c for c in dataframe if c not in ['income']] + ['income']]\n",
        "dataframe.head(10)\n",
        "\n",
        "X = dataframe.iloc[:, 0:88].values\n",
        "y = dataframe.iloc[:, 88].values\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2)\n",
        "X = df.drop('income', axis=1)\n",
        "y = df['income']\n",
        "\n",
        "sc = StandardScaler()\n",
        "X_train = sc.fit_transform(X_train)\n",
        "X_test = sc.transform(X_test)\n",
        "\n",
        "unique_income = df['income'].unique()\n",
        "unique_sex = df['gender'].unique()\n",
        "unique_race = df['race'].unique()\n",
        "unique_workclass = df['workclass'].unique()\n",
        "unique_marital_status = df['marital-status'].unique()\n",
        "\n",
        "net_dat = MLPClassifier(hidden_layer_sizes=(8,), max_iter=1000, random_state=42)\n",
        "net_dat.fit(X_train, y_train)\n",
        "plt.figure(figsize=(10, 8))\n",
        "plt.imshow(net_dat.coefs_[0], interpolation='none', cmap='viridis')\n",
        "plt.yticks(range(len(X.columns)), X.columns)\n",
        "plt.xlabel('Hidden Layer Neurons')\n",
        "plt.colorbar()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "zfmpa-XCHA0_",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 512
        },
        "outputId": "6745b66a-2ed9-4c48-afbd-25e5a003fd03"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3801\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3802\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3803\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 'race'",
            "\nThe above exception was the direct cause of the following exception:\n",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-27-3ed54b2d36a8>\u001b[0m in \u001b[0;36m<cell line: 26>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mcol\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcategory_col\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m     \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcol\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlabelEncoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcol\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m category_col_1 =['workclass', 'education', 'occupation',\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3805\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnlevels\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3806\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3807\u001b[0;31m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3808\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3809\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3802\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3803\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3804\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3805\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3806\u001b[0m                 \u001b[0;31m# If we have a listlike key, _check_indexing_error will raise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 'race'"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#8: CLUSTERING\n"
      ],
      "metadata": {
        "id": "IC2zaxkxHsRZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Generate some random data for demonstration\n",
        "np.random.seed(42)\n",
        "X = np.random.rand(100, 1) * 10\n",
        "Y = 3 * X + np.random.randn(100, 1) * 2\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=0)\n",
        "\n",
        "# Create and fit the linear regression model\n",
        "model = LinearRegression()\n",
        "model.fit(X_train, Y_train)\n",
        "\n",
        "# Make predictions on the test set\n",
        "Y_pred = model.predict(X_test)\n",
        "\n",
        "# Evaluate the model\n",
        "mse = mean_squared_error(Y_test, Y_pred)\n",
        "r2 = r2_score(Y_test, Y_pred)\n",
        "\n",
        "print(f'Mean Squared Error: {mse}')\n",
        "print(f'R-squared: {r2}')"
      ],
      "metadata": {
        "id": "a9seeSScH9Qv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a98ea3f4-57d5-45b4-ee48-6f87f5d1d528"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mean Squared Error: 2.6801412165451053\n",
            "R-squared: 0.9501425422637257\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#9: REGRESSION MODELLING\n"
      ],
      "metadata": {
        "id": "FfmwTAk0IXlZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import statsmodels.api as sm\n",
        "import pandas as pd\n",
        "\n",
        "# Assuming you have a dataframe df with dependent variable 'Y' and independent variables 'X1', 'X2', ...\n",
        "# Generate some random data for demonstration\n",
        "np.random.seed(42)\n",
        "df = pd.DataFrame({'Y': 3 * X.flatten() + np.random.randn(100) * 2, 'X1': X.flatten(), 'X2': np.random.randn(100)})\n",
        "\n",
        "# Function for stepwise regression\n",
        "def stepwise_selection(X, y, initial_list=[], threshold_in=0.01, threshold_out=0.05, verbose=True):\n",
        "    included = list(initial_list)\n",
        "    while True:\n",
        "        changed = False\n",
        "        # Forward step\n",
        "        excluded = list(set(X.columns) - set(included))\n",
        "        new_pval = pd.Series(index=excluded)\n",
        "        for new_column in excluded:\n",
        "            model = sm.OLS(y, sm.add_constant(pd.DataFrame(X[included + [new_column]]))).fit()\n",
        "            new_pval[new_column] = model.pvalues[new_column]\n",
        "        best_pval = new_pval.min()\n",
        "        if best_pval < threshold_in:\n",
        "            best_feature = new_pval.idxmin()\n",
        "            included.append(best_feature)\n",
        "            changed = True\n",
        "            if verbose:\n",
        "                print(f'Add  {best_feature} with p-value {best_pval}')\n",
        "        # Backward step\n",
        "        model = sm.OLS(y, sm.add_constant(pd.DataFrame(X[included]))).fit()\n",
        "        pvalues = model.pvalues.iloc[1:]\n",
        "        worst_pval = pvalues.max()\n",
        "        if worst_pval > threshold_out:\n",
        "            changed = True\n",
        "            worst_feature = pvalues.idxmax()\n",
        "            included.remove(worst_feature)\n",
        "            if verbose:\n",
        "                print(f'Drop {worst_feature} with p-value {worst_pval}')\n",
        "        if not changed:\n",
        "            break\n",
        "    return included\n",
        "\n",
        "# Separate target variable and features\n",
        "y = df['Y']\n",
        "X = df.drop('Y', axis=1)\n",
        "\n",
        "# Perform stepwise regression\n",
        "selected_features = stepwise_selection(X, y)\n",
        "\n",
        "print(\"Selected features:\", selected_features)\n"
      ],
      "metadata": {
        "id": "Lj6Sduq-IYzm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d797ef7a-347a-4738-c226-54317842a42f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Add  X1 with p-value 7.030235624093543e-72\n",
            "Selected features: ['X1']\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-9-f3a8c0629358>:16: FutureWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
            "  new_pval = pd.Series(index=excluded)\n",
            "<ipython-input-9-f3a8c0629358>:16: FutureWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
            "  new_pval = pd.Series(index=excluded)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#10: DIMENSION REDUCTION DIMENSION REDUCTION\n"
      ],
      "metadata": {
        "id": "ZOhKEkfRIt7X"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 1 Demonstrate How you will  Identify Multicollinearity R/Python\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "#create DataFrame\n",
        "df = pd.DataFrame({'rating': [90, 85, 82, 88, 94, 90, 76, 75, 87, 86],\n",
        "                   'points': [25, 20, 14, 16, 27, 20, 12, 15, 14, 19],\n",
        "                   'assists': [5, 7, 7, 8, 5, 7, 6, 9, 9, 5],\n",
        "                   'rebounds': [11, 8, 10, 6, 6, 9, 6, 10, 10, 7]})\n",
        "\n",
        "#view DataFrame\n",
        "print(df)\n",
        "\n",
        "#variance_inflation_factor() function from the statsmodels library:\n",
        "\n",
        "from patsy import dmatrices\n",
        "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
        "\n",
        "#find design matrix for regression model using 'rating' as response variable\n",
        "y, X = dmatrices('rating ~ points+assists+rebounds', data=df, return_type='dataframe')\n",
        "\n",
        "#create DataFrame to hold VIF values\n",
        "vif_df = pd.DataFrame()\n",
        "vif_df['variable'] = X.columns\n",
        "\n",
        "#calculate VIF for each predictor variable\n",
        "vif_df['VIF'] = [variance_inflation_factor(X.values, i) for i in range(X.shape[1])]\n",
        "\n",
        "#view VIF for each predictor variable\n",
        "print(vif_df)\n",
        "\n",
        "\n",
        "# 2  Demonstrate HOW you’ll apply PRINCIPAL COMPONENTS ANALYSIS Using R/Python\n",
        "\n",
        "# importing required libraries\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "\n",
        "# importing or loading the dataset\n",
        "dataset = pd.read_csv('/content/drive/MyDrive/dataset/Auto Sales data.csv')\n",
        "\n",
        "# distributing the dataset into two components X and Y\n",
        "X = dataset.iloc[:, 0:13].values\n",
        "y = dataset.iloc[:, 13].values\n",
        "\n",
        "# Splitting the X and Y into the\n",
        "# Training set and Testing set\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 0)\n",
        "\n",
        "# performing preprocessing part\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "sc = StandardScaler()\n",
        "\n",
        "X_train = sc.fit_transform(X_train)\n",
        "X_test = sc.transform(X_test)\n",
        "\n",
        "# Applying PCA function on training\n",
        "# and testing set of X component\n",
        "from sklearn.decomposition import PCA\n",
        "\n",
        "pca = PCA(n_components = 2)\n",
        "\n",
        "X_train = pca.fit_transform(X_train)\n",
        "X_test = pca.transform(X_test)\n",
        "\n",
        "explained_variance = pca.explained_variance_ratio_\n",
        "\n",
        "# Fitting Logistic Regression To the training set\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "classifier = LogisticRegression(random_state = 0)\n",
        "classifier.fit(X_train, y_train)\n",
        "# Predicting the test set result using\n",
        "# predict function under LogisticRegression\n",
        "y_pred = classifier.predict(X_test)\n",
        "\n",
        "# making confusion matrix between\n",
        "# test set of Y and predicted value.\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "\n",
        "# Predicting the training set\n",
        "# result through scatter plot\n",
        "from matplotlib.colors import ListedColormap\n",
        "\n",
        "X_set, y_set = X_train, y_train\n",
        "X1, X2 = np.meshgrid(np.arange(start = X_set[:, 0].min() - 1,\n",
        "\t\t\t\t\tstop = X_set[:, 0].max() + 1, step = 0.01),\n",
        "\t\t\t\t\tnp.arange(start = X_set[:, 1].min() - 1,\n",
        "\t\t\t\t\tstop = X_set[:, 1].max() + 1, step = 0.01))\n",
        "\n",
        "plt.contourf(X1, X2, classifier.predict(np.array([X1.ravel(),\n",
        "\t\t\tX2.ravel()]).T).reshape(X1.shape), alpha = 0.75,\n",
        "\t\t\tcmap = ListedColormap(('yellow', 'white', 'aquamarine')))\n",
        "\n",
        "plt.xlim(X1.min(), X1.max())\n",
        "plt.ylim(X2.min(), X2.max())\n",
        "\n",
        "for i, j in enumerate(np.unique(y_set)):\n",
        "\tplt.scatter(X_set[y_set == j, 0], X_set[y_set == j, 1],\n",
        "\t\t\t\tc = ListedColormap(('red', 'green', 'blue'))(i), label = j)\n",
        "\n",
        "plt.title('Logistic Regression (Training set)')\n",
        "plt.xlabel('PC1') # for Xlabel\n",
        "plt.ylabel('PC2') # for Ylabel\n",
        "plt.legend() # to show legend\n",
        "\n",
        "# show scatter plot\n",
        "plt.show()\n",
        "\n",
        "# Visualising the Test set results through scatter plot\n",
        "from matplotlib.colors import ListedColormap\n",
        "\n",
        "X_set, y_set = X_test, y_test\n",
        "\n",
        "X1, X2 = np.meshgrid(np.arange(start = X_set[:, 0].min() - 1,\n",
        "\t\t\t\t\tstop = X_set[:, 0].max() + 1, step = 0.01),\n",
        "\t\t\t\t\tnp.arange(start = X_set[:, 1].min() - 1,\n",
        "\t\t\t\t\tstop = X_set[:, 1].max() + 1, step = 0.01))\n",
        "\n",
        "plt.contourf(X1, X2, classifier.predict(np.array([X1.ravel(),\n",
        "\t\t\tX2.ravel()]).T).reshape(X1.shape), alpha = 0.75,\n",
        "\t\t\tcmap = ListedColormap(('yellow', 'white', 'aquamarine')))\n",
        "\n",
        "plt.xlim(X1.min(), X1.max())\n",
        "plt.ylim(X2.min(), X2.max())\n",
        "\n",
        "for i, j in enumerate(np.unique(y_set)):\n",
        "\tplt.scatter(X_set[y_set == j, 0], X_set[y_set == j, 1],\n",
        "\t\t\t\tc = ListedColormap(('red', 'green', 'blue'))(i), label = j)\n",
        "\n",
        "# title for scatter plot\n",
        "plt.title('Logistic Regression (Test set)')\n",
        "plt.xlabel('PC1') # for Xlabel\n",
        "plt.ylabel('PC2') # for Ylabel\n",
        "plt.legend()\n",
        "\n",
        "# show scatter plot\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "Wbbq5AlxIu76",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 668
        },
        "outputId": "c0ce44f9-643e-42df-baf0-e2f183b86099"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   rating  points  assists  rebounds\n",
            "0      90      25        5        11\n",
            "1      85      20        7         8\n",
            "2      82      14        7        10\n",
            "3      88      16        8         6\n",
            "4      94      27        5         6\n",
            "5      90      20        7         9\n",
            "6      76      12        6         6\n",
            "7      75      15        9        10\n",
            "8      87      14        9        10\n",
            "9      86      19        5         7\n",
            "    variable         VIF\n",
            "0  Intercept  101.258171\n",
            "1     points    1.763977\n",
            "2    assists    1.959104\n",
            "3   rebounds    1.175030\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-10-b136bb3e66e6>\u001b[0m in \u001b[0;36m<cell line: 57>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[0msc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mStandardScaler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 57\u001b[0;31m \u001b[0mX_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     58\u001b[0m \u001b[0mX_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/utils/_set_output.py\u001b[0m in \u001b[0;36mwrapped\u001b[0;34m(self, X, *args, **kwargs)\u001b[0m\n\u001b[1;32m    138\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mwraps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    139\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mwrapped\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 140\u001b[0;31m         \u001b[0mdata_to_wrap\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    141\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_to_wrap\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    142\u001b[0m             \u001b[0;31m# only wrap the first output for cross decomposition\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/base.py\u001b[0m in \u001b[0;36mfit_transform\u001b[0;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[1;32m    876\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0my\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    877\u001b[0m             \u001b[0;31m# fit method of arity 1 (unsupervised transformation)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 878\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    879\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    880\u001b[0m             \u001b[0;31m# fit method of arity 2 (supervised transformation)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/preprocessing/_data.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    822\u001b[0m         \u001b[0;31m# Reset internal state before fitting\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    823\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 824\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpartial_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    825\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    826\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mpartial_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/preprocessing/_data.py\u001b[0m in \u001b[0;36mpartial_fit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    859\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    860\u001b[0m         \u001b[0mfirst_call\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"n_samples_seen_\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 861\u001b[0;31m         X = self._validate_data(\n\u001b[0m\u001b[1;32m    862\u001b[0m             \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    863\u001b[0m             \u001b[0maccept_sparse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"csr\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"csc\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/base.py\u001b[0m in \u001b[0;36m_validate_data\u001b[0;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[1;32m    563\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Validation should be done on X, y or both.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    564\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mno_val_X\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mno_val_y\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 565\u001b[0;31m             \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"X\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mcheck_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    566\u001b[0m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    567\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mno_val_X\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mno_val_y\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[1;32m    877\u001b[0m                     \u001b[0marray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mxp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    878\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 879\u001b[0;31m                     \u001b[0marray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_asarray_with_order\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mxp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    880\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mComplexWarning\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mcomplex_warning\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    881\u001b[0m                 raise ValueError(\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/utils/_array_api.py\u001b[0m in \u001b[0;36m_asarray_with_order\u001b[0;34m(array, dtype, order, copy, xp)\u001b[0m\n\u001b[1;32m    183\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mxp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m\"numpy\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"numpy.array_api\"\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    184\u001b[0m         \u001b[0;31m# Use NumPy API to support order\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 185\u001b[0;31m         \u001b[0marray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    186\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mxp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: could not convert string to float: 'Shipped'"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#11: LOGISTIC REGRESSION MODELLING\n"
      ],
      "metadata": {
        "id": "hI1TLl_WMRjJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#How to Perform Logistic Regression Using Python\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import statsmodels.api as sm\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Load the bank dataset (replace 'bank.csv' with the actual path to your dataset)\n",
        "bank_data = pd.read_csv('/content/bank.csv')\n",
        "\n",
        "# For simplicity, separate the variables into predictor variables X and response variable y\n",
        "X = pd.DataFrame(bank_data[['duration', 'pdays']])\n",
        "X = sm.add_constant(X)\n",
        "y = bank_data['deposit'].map({'yes': 1, 'no': 0})  # Convert 'deposit' to binary\n",
        "\n",
        "# Split the data into training and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Perform logistic regression on the training set\n",
        "logreg_bank = sm.Logit(y_train, X_train).fit()\n",
        "\n",
        "# View the model results for the training set\n",
        "logreg_bank.summary2()\n",
        "\n",
        "# Create a synthetic test dataset\n",
        "np.random.seed(42)  # For reproducibility\n",
        "num_samples = 1000\n",
        "\n",
        "test_data = {\n",
        "    'duration': np.random.randint(1, 100, num_samples),\n",
        "    'pdays': np.random.randint(1, 30, num_samples),\n",
        "}\n",
        "\n",
        "test_df = pd.DataFrame(test_data)\n",
        "\n",
        "# Add a constant to the test dataset\n",
        "X_test_synthetic = sm.add_constant(test_df)\n",
        "\n",
        "# Predict using the logistic regression model\n",
        "y_pred_synthetic = logreg_bank.predict(X_test_synthetic)\n",
        "\n",
        "# Convert predicted probabilities to binary predictions\n",
        "y_pred_binary_synthetic = (y_pred_synthetic >= 0.5).astype(int)\n",
        "\n",
        "# View the predictions\n",
        "synthetic_predictions = pd.DataFrame({'Predicted Probability': y_pred_synthetic, 'Predicted Binary': y_pred_binary_synthetic})\n",
        "print(synthetic_predictions)\n",
        "\n",
        "#How to Perform Poisson Regression Using Python\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import statsmodels.api as sm\n",
        "\n",
        "# Load the bank dataset (replace 'bank.csv' with the actual path to your dataset)\n",
        "bank_data = pd.read_csv('/content/bank.csv')\n",
        "\n",
        "# For simplicity, let's use the 'previous' variable as the predictor and 'duration' as the response\n",
        "X = pd.DataFrame(bank_data[['previous']])\n",
        "X = sm.add_constant(X)\n",
        "y = pd.DataFrame(bank_data['duration'])  # Assuming 'duration' is the response variable\n",
        "\n",
        "# Convert categorical variable 'deposit' to binary\n",
        "y_binary = (y > y.median()).astype(int)\n",
        "\n",
        "# Run Poisson regression using GLM\n",
        "poisreg_bank = sm.GLM(y_binary, X, family=sm.families.Poisson()).fit()\n",
        "\n",
        "# View the model results\n",
        "poisreg_bank.summary()"
      ],
      "metadata": {
        "id": "CcvbCHkXMWo9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#12: ASSOCIATION RULES"
      ],
      "metadata": {
        "id": "i9ux1Cu0Wh7p"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "##Demonstrate How you will Identify Multicollinearity Python\n",
        "\n",
        "import pandas as pd\n",
        "import statsmodels.api as sm\n",
        "import statsmodels.stats.outliers_influence as inf\n",
        "\n",
        "# Load the bank dataset (replace 'bank.csv' with the actual path to your dataset)\n",
        "bank_data = pd.read_csv('/content/bank.csv')\n",
        "\n",
        "# Replace these columns with your actual predictor variable names\n",
        "predictor_columns = [\"age\", \"balance\", \"duration\"]\n",
        "\n",
        "# Extract the predictor variables into their own data frame\n",
        "X = pd.DataFrame(bank_data[predictor_columns])\n",
        "\n",
        "# Create a scatterplot matrix\n",
        "pd.plotting.scatter_matrix(X)\n",
        "\n",
        "# Remove records with missing values\n",
        "X = X.dropna()\n",
        "\n",
        "# Add the constant term\n",
        "X = sm.add_constant(X)\n",
        "\n",
        "# Calculate VIF values\n",
        "vif_values = [inf.variance_inflation_factor(X.values, i) for i in range(1, X.shape[1])]\n",
        "vif_values\n",
        "\n",
        "##Demonstrate How you'll apply Principal Components Analysis Using Python\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.decomposition import PCA\n",
        "\n",
        "# Load the bank dataset (replace 'bank.csv' with the actual path to your dataset)\n",
        "bank_data = pd.read_csv('/content/bank.csv')\n",
        "\n",
        "# Replace these columns with your actual predictor variable names\n",
        "predictor_columns = [\"age\", \"balance\", \"duration\"]\n",
        "\n",
        "# Extract the predictor variables into their own data frame\n",
        "X = bank_data[predictor_columns]\n",
        "\n",
        "# Standardize the data\n",
        "scaler = StandardScaler()\n",
        "X_standardized = scaler.fit_transform(X)\n",
        "\n",
        "# Obtain the correlation matrix\n",
        "correlation_matrix = pd.DataFrame(X_standardized, columns=predictor_columns).corr()\n",
        "\n",
        "# Print the correlation matrix\n",
        "print(correlation_matrix)\n",
        "\n",
        "# Run PCA with the maximum number of components (3 in this case)\n",
        "pca = PCA(n_components=min(X.shape[0], X.shape[1]))\n",
        "principal_components = pca.fit_transform(X_standardized)\n",
        "\n",
        "# Get the variability explained by each component\n",
        "explained_variance_ratios = pca.explained_variance_ratio_\n",
        "print(\"Variability explained by each component:\", explained_variance_ratios)\n",
        "\n",
        "# Get the cumulative variability explained\n",
        "cumulative_variability = np.cumsum(explained_variance_ratios)\n",
        "print(\"Cumulative variability explained:\", cumulative_variability)\n",
        "\n",
        "##Demonstrate How you'll apply Principal Components Analysis Using Python\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.decomposition import PCA\n",
        "\n",
        "# Load the bank dataset (replace 'bank.csv' with the actual path to your dataset)\n",
        "bank_data = pd.read_csv('/content/bank.csv')\n",
        "\n",
        "# Replace these columns with your actual predictor variable names\n",
        "predictor_columns = [\"age\", \"balance\", \"duration\"]\n",
        "\n",
        "# Extract the predictor variables into their own data frame\n",
        "X = bank_data[predictor_columns]\n",
        "\n",
        "# Standardize the data\n",
        "scaler = StandardScaler()\n",
        "X_standardized = scaler.fit_transform(X)\n",
        "\n",
        "# Obtain the correlation matrix\n",
        "correlation_matrix = pd.DataFrame(X_standardized, columns=predictor_columns).corr()\n",
        "\n",
        "# Print the correlation matrix\n",
        "print(correlation_matrix)\n",
        "\n",
        "# Run PCA with the maximum number of components (3 in this case)\n",
        "pca = PCA(n_components=min(X.shape[0], X.shape[1]))\n",
        "principal_components = pca.fit_transform(X_standardized)\n",
        "\n",
        "# Get the variability explained by each component\n",
        "explained_variance_ratios = pca.explained_variance_ratio_\n",
        "print(\"Variability explained by each component:\", explained_variance_ratios)\n",
        "\n",
        "# Get the cumulative variability explained\n",
        "cumulative_variability = np.cumsum(explained_variance_ratios)\n",
        "print(\"Cumulative variability explained:\", cumulative_variability)\n",
        "\n",
        "\n",
        "## 12.2 How to Apply the Confidence Difference Criterion Using Python\n",
        "import pandas as pd\n",
        "from apyori import apriori\n",
        "\n",
        "# Load the bank dataset (replace 'bank.csv' with the actual path to your dataset)\n",
        "bank_data = pd.read_csv('/content/bank.csv')\n",
        "\n",
        "# Subset the data to include only the relevant columns\n",
        "min_bank = bank_data[[\"job\", \"marital\", \"education\", \"default\", \"housing\", \"loan\", \"contact\", \"poutcome\", \"deposit\"]]\n",
        "\n",
        "# Convert categorical variables to string for apyori\n",
        "min_bank = min_bank.astype(str)\n",
        "\n",
        "# Flatten the tables for apyori\n",
        "transactions = []\n",
        "for column in min_bank.columns:\n",
        "    transactions.append([(str(item),) for item in pd.unique(min_bank[column])])\n",
        "\n",
        "# Run apriori algorithm with confidence difference criterion\n",
        "rules_confdiff = apriori(transactions, min_support=0.01, min_confidence=0.4, min_lift=1, min_length=2)\n",
        "\n",
        "# Display all rules before filtering\n",
        "for rule in rules_confdiff:\n",
        "    print(rule)\n",
        "\n",
        "# Filter rules based on confidence difference criterion\n",
        "confidence_difference_threshold = 0.1  # Set your desired confidence difference threshold\n",
        "filtered_rules_confdiff = [\n",
        "    rule for rule in rules_confdiff\n",
        "    if any(\n",
        "        abs(stat.confidence - rule.ordered_statistics[i].confidence) >= confidence_difference_threshold\n",
        "        for i, stat in enumerate(rule.ordered_statistics)\n",
        "    )\n",
        "]\n",
        "\n",
        "# Display the filtered rules\n",
        "for rule in filtered_rules_confdiff[:10]:\n",
        "    print(rule)"
      ],
      "metadata": {
        "id": "VU1y7hyQWmBt"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}